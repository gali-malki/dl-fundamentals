{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "7d6d3cf5-82f0-4281-b10c-ea14c2e0eeb6",
   "metadata": {},
   "source": [
    "# Unit 6. Essential Deep Learning Tips & Tricks\n",
    "\n",
    "# Exercise 1: Learning Rate Warmup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "e80fef60",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pytorch_lightning as L\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "import torchmetrics\n",
    "from pytorch_lightning.loggers import CSVLogger\n",
    "\n",
    "from shared_utilities import CustomDataModule, PyTorchMLP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "729e8e09-5aa1-4809-9497-46e0b8757608",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_epochs = 100"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a85f6cef-c6d5-4401-93c1-5c9103a08aee",
   "metadata": {},
   "source": [
    "## Cosine annealing with 1-cycle schedule"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "238636d3-b536-4e08-8902-c5dd4b7e7090",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "model = torch.nn.Linear(1, 1)\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr=0.1)\n",
    "scheduler = torch.optim.lr_scheduler.CosineAnnealingLR(optimizer, T_max=num_epochs)\n",
    "lrs = []\n",
    "\n",
    "for i in range(num_epochs):\n",
    "    optimizer.step()\n",
    "    lrs.append(optimizer.param_groups[0][\"lr\"])\n",
    "    scheduler.step()\n",
    "\n",
    "plt.ylabel(\"Learning rate\")\n",
    "plt.xlabel(\"Epoch\")\n",
    "plt.plot(lrs)\n",
    "#plt.savefig(\"cosine-1cycle-epoch.pdf\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "9a8f8387-95a9-42a9-a808-69225f3fb078",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/galimalki/anaconda3/envs/conda/lib/python3.8/site-packages/pl_bolts/__init__.py:11: FutureWarning: In the future `np.object` will be defined as the corresponding NumPy scalar.\n",
      "  if not hasattr(numpy, tp_name):\n",
      "/Users/galimalki/anaconda3/envs/conda/lib/python3.8/site-packages/pl_bolts/__init__.py:11: FutureWarning: In the future `np.bool` will be defined as the corresponding NumPy scalar.\n",
      "  if not hasattr(numpy, tp_name):\n",
      "/Users/galimalki/anaconda3/envs/conda/lib/python3.8/site-packages/pl_bolts/models/self_supervised/amdim/amdim_module.py:34: UnderReviewWarning: The feature generate_power_seq is currently marked under review. The compatibility with other Lightning projects is not guaranteed and API may change at any time. The API and functionality may change without warning in future releases. More details: https://lightning-bolts.readthedocs.io/en/latest/stability.html\n",
      "  \"lr_options\": generate_power_seq(LEARNING_RATE_CIFAR, 11),\n",
      "/Users/galimalki/anaconda3/envs/conda/lib/python3.8/site-packages/pl_bolts/models/self_supervised/amdim/amdim_module.py:92: UnderReviewWarning: The feature FeatureMapContrastiveTask is currently marked under review. The compatibility with other Lightning projects is not guaranteed and API may change at any time. The API and functionality may change without warning in future releases. More details: https://lightning-bolts.readthedocs.io/en/latest/stability.html\n",
      "  contrastive_task: Union[FeatureMapContrastiveTask] = FeatureMapContrastiveTask(\"01, 02, 11\"),\n",
      "/Users/galimalki/anaconda3/envs/conda/lib/python3.8/site-packages/pl_bolts/losses/self_supervised_learning.py:228: UnderReviewWarning: The feature AmdimNCELoss is currently marked under review. The compatibility with other Lightning projects is not guaranteed and API may change at any time. The API and functionality may change without warning in future releases. More details: https://lightning-bolts.readthedocs.io/en/latest/stability.html\n",
      "  self.nce_loss = AmdimNCELoss(tclip)\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from pl_bolts.optimizers.lr_scheduler import LinearWarmupCosineAnnealingLR\n",
    "\n",
    "\n",
    "model = torch.nn.Linear(1, 1)\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr=0.1)\n",
    "scheduler = torch.optim.lr_scheduler.CosineAnnealingLR(optimizer, T_max=num_epochs)\n",
    "lrs = []\n",
    "\n",
    "for i in range(num_epochs):\n",
    "    optimizer.step()\n",
    "    lrs.append(optimizer.param_groups[0][\"lr\"])\n",
    "    scheduler.step()\n",
    "\n",
    "plt.ylabel(\"Learning rate\")\n",
    "plt.xlabel(\"Epoch\")\n",
    "plt.plot(lrs)\n",
    "#plt.savefig(\"cosine-1cycle-epoch.pdf\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "26845f11-4a0d-48f3-818a-22e4093b79ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "class LightningModel(L.LightningModule):\n",
    "    def __init__(self, model, learning_rate, num_epochs):  # New!\n",
    "        super().__init__()\n",
    "\n",
    "        self.learning_rate = learning_rate\n",
    "        self.num_epochs = num_epochs  # New!\n",
    "        self.model = model\n",
    "\n",
    "        self.save_hyperparameters(ignore=[\"model\"])\n",
    "\n",
    "        self.train_acc = torchmetrics.Accuracy(task=\"multiclass\", num_classes=2)\n",
    "        self.val_acc = torchmetrics.Accuracy(task=\"multiclass\", num_classes=2)\n",
    "        self.test_acc = torchmetrics.Accuracy(task=\"multiclass\", num_classes=2)\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.model(x)\n",
    "\n",
    "    def _shared_step(self, batch):\n",
    "        features, true_labels = batch\n",
    "        logits = self(features)\n",
    "\n",
    "        loss = F.cross_entropy(logits, true_labels)\n",
    "        predicted_labels = torch.argmax(logits, dim=1)\n",
    "        return loss, true_labels, predicted_labels\n",
    "\n",
    "    def training_step(self, batch, batch_idx):\n",
    "        loss, true_labels, predicted_labels = self._shared_step(batch)\n",
    "\n",
    "        self.log(\"train_loss\", loss)\n",
    "        self.train_acc(predicted_labels, true_labels)\n",
    "        self.log(\n",
    "            \"train_acc\", self.train_acc, prog_bar=True, on_epoch=True, on_step=False\n",
    "        )\n",
    "        return loss\n",
    "\n",
    "    def validation_step(self, batch, batch_idx):\n",
    "        loss, true_labels, predicted_labels = self._shared_step(batch)\n",
    "\n",
    "        self.log(\"val_loss\", loss, prog_bar=True)\n",
    "        self.val_acc(predicted_labels, true_labels)\n",
    "        self.log(\"val_acc\", self.val_acc, prog_bar=True)\n",
    "\n",
    "    def test_step(self, batch, batch_idx):\n",
    "        loss, true_labels, predicted_labels = self._shared_step(batch)\n",
    "        self.test_acc(predicted_labels, true_labels)\n",
    "        self.log(\"test_acc\", self.test_acc)\n",
    "\n",
    "    def configure_optimizers(self): # New! \n",
    "        opt = torch.optim.SGD(self.parameters(), lr=self.learning_rate)\n",
    "        sch = LinearWarmupCosineAnnealingLR(\n",
    "            opt, \n",
    "            warmup_epochs=self.num_epochs*0.25, \n",
    "            max_epochs=self.num_epochs,\n",
    "            warmup_start_lr=0.0)\n",
    "\n",
    "        return {\n",
    "            \"optimizer\": opt,\n",
    "            \"lr_scheduler\": {\n",
    "                \"scheduler\": sch,\n",
    "                \"monitor\": \"train_loss\",\n",
    "                \"interval\": \"epoch\",\n",
    "                \"frequency\": 1,\n",
    "            },\n",
    "        }"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "48cce5d5-4bb7-4a18-b76e-4fcb58a342cc",
   "metadata": {},
   "source": [
    "# !!! No Modification Required Below Here !!!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "aa7bcf14-8046-4213-accf-544b67e74883",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Global seed set to 123\n",
      "GPU available: True (mps), used: False\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "/Users/galimalki/anaconda3/envs/conda/lib/python3.8/site-packages/pytorch_lightning/trainer/setup.py:201: UserWarning: MPS available but not used. Set `accelerator` and `devices` using `Trainer(accelerator='mps', devices=1)`.\n",
      "  rank_zero_warn(\n"
     ]
    }
   ],
   "source": [
    "L.seed_everything(123)\n",
    "dm = CustomDataModule()\n",
    "\n",
    "pytorch_model = PyTorchMLP(num_features=100, num_classes=2)\n",
    "lightning_model = LightningModel(\n",
    "    model=pytorch_model,\n",
    "    learning_rate=0.1,\n",
    "    num_epochs=num_epochs) # New!\n",
    "\n",
    "trainer = L.Trainer(\n",
    "    max_epochs=num_epochs,\n",
    "    accelerator=\"cpu\",\n",
    "    devices=\"auto\",\n",
    "    logger=CSVLogger(save_dir=\"logs/\", name=\"my-model\"),\n",
    "    deterministic=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14d23b49-4c47-4bb1-bf6c-b87aabf0b22d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/l_/2tmjtmmd6td7fl90md2dbxcc0000gn/T/ipykernel_42357/3563877523.py:50: UnderReviewWarning: The feature LinearWarmupCosineAnnealingLR is currently marked under review. The compatibility with other Lightning projects is not guaranteed and API may change at any time. The API and functionality may change without warning in future releases. More details: https://lightning-bolts.readthedocs.io/en/latest/stability.html\n",
      "  sch = LinearWarmupCosineAnnealingLR(\n",
      "\n",
      "  | Name      | Type               | Params\n",
      "-------------------------------------------------\n",
      "0 | model     | PyTorchMLP         | 15.3 K\n",
      "1 | train_acc | MulticlassAccuracy | 0     \n",
      "2 | val_acc   | MulticlassAccuracy | 0     \n",
      "3 | test_acc  | MulticlassAccuracy | 0     \n",
      "-------------------------------------------------\n",
      "15.3 K    Trainable params\n",
      "0         Non-trainable params\n",
      "15.3 K    Total params\n",
      "0.061     Total estimated model params size (MB)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                                                                                                                                                                "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/galimalki/anaconda3/envs/conda/lib/python3.8/site-packages/pytorch_lightning/trainer/connectors/data_connector.py:224: PossibleUserWarning: The dataloader, val_dataloader 0, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 10 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.\n",
      "  rank_zero_warn(\n",
      "/Users/galimalki/anaconda3/envs/conda/lib/python3.8/site-packages/pytorch_lightning/trainer/connectors/data_connector.py:224: PossibleUserWarning: The dataloader, train_dataloader, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 10 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.\n",
      "  rank_zero_warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0:  90%|          | 450/500 [00:01<00:00, 304.68it/s, loss=0.757, v_num=2]\n",
      "Validation: 0it [00:00, ?it/s]\u001b[A\n",
      "Validation:   0%|                                                                                                                                        | 0/50 [00:00<?, ?it/s]\u001b[A\n",
      "Validation DataLoader 0:   0%|                                                                                                                           | 0/50 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 0:  90%|          | 451/500 [00:01<00:00, 302.92it/s, loss=0.757, v_num=2]\u001b[A\n",
      "Epoch 0:  90%|          | 452/500 [00:01<00:00, 302.99it/s, loss=0.757, v_num=2]\u001b[A\n",
      "Epoch 0:  91%|          | 453/500 [00:01<00:00, 303.15it/s, loss=0.757, v_num=2]\u001b[A\n",
      "Epoch 0:  91%|         | 454/500 [00:01<00:00, 303.23it/s, loss=0.757, v_num=2]\u001b[A\n",
      "Epoch 0:  91%|         | 455/500 [00:01<00:00, 303.27it/s, loss=0.757, v_num=2]\u001b[A\n",
      "Epoch 0:  91%|         | 456/500 [00:01<00:00, 303.30it/s, loss=0.757, v_num=2]\u001b[A\n",
      "Epoch 0:  91%|         | 457/500 [00:01<00:00, 303.34it/s, loss=0.757, v_num=2]\u001b[A\n",
      "Epoch 0:  92%|         | 458/500 [00:01<00:00, 303.36it/s, loss=0.757, v_num=2]\u001b[A\n",
      "Epoch 0:  92%|        | 459/500 [00:01<00:00, 303.01it/s, loss=0.757, v_num=2]\u001b[A\n",
      "Epoch 0:  92%|        | 460/500 [00:01<00:00, 303.11it/s, loss=0.757, v_num=2]\u001b[A\n",
      "Epoch 0:  92%|        | 461/500 [00:01<00:00, 302.92it/s, loss=0.757, v_num=2]\u001b[A\n",
      "Epoch 0:  92%|        | 462/500 [00:01<00:00, 302.93it/s, loss=0.757, v_num=2]\u001b[A\n",
      "Epoch 0:  93%|       | 463/500 [00:01<00:00, 302.64it/s, loss=0.757, v_num=2]\u001b[A\n",
      "Epoch 0:  93%|       | 464/500 [00:01<00:00, 302.53it/s, loss=0.757, v_num=2]\u001b[A\n",
      "Epoch 0:  93%|       | 465/500 [00:01<00:00, 302.54it/s, loss=0.757, v_num=2]\u001b[A\n",
      "Epoch 0:  93%|       | 466/500 [00:01<00:00, 302.54it/s, loss=0.757, v_num=2]\u001b[A\n",
      "Epoch 0:  93%|       | 467/500 [00:01<00:00, 302.56it/s, loss=0.757, v_num=2]\u001b[A\n",
      "Epoch 0:  94%|      | 468/500 [00:01<00:00, 302.58it/s, loss=0.757, v_num=2]\u001b[A\n",
      "Epoch 0:  94%|      | 469/500 [00:01<00:00, 302.69it/s, loss=0.757, v_num=2]\u001b[A\n",
      "Epoch 0:  94%|      | 470/500 [00:01<00:00, 302.62it/s, loss=0.757, v_num=2]\u001b[A\n",
      "Epoch 0:  94%|      | 471/500 [00:01<00:00, 302.57it/s, loss=0.757, v_num=2]\u001b[A\n",
      "Epoch 0:  94%|      | 472/500 [00:01<00:00, 302.54it/s, loss=0.757, v_num=2]\u001b[A\n",
      "Epoch 0:  95%|     | 473/500 [00:01<00:00, 302.55it/s, loss=0.757, v_num=2]\u001b[A\n",
      "Epoch 0:  95%|     | 474/500 [00:01<00:00, 302.47it/s, loss=0.757, v_num=2]\u001b[A\n",
      "Epoch 0:  95%|     | 475/500 [00:01<00:00, 302.57it/s, loss=0.757, v_num=2]\u001b[A\n",
      "Epoch 0:  95%|     | 476/500 [00:01<00:00, 302.56it/s, loss=0.757, v_num=2]\u001b[A\n",
      "Epoch 0:  95%|     | 477/500 [00:01<00:00, 302.66it/s, loss=0.757, v_num=2]\u001b[A\n",
      "Epoch 0:  96%|    | 478/500 [00:01<00:00, 302.81it/s, loss=0.757, v_num=2]\u001b[A\n",
      "Epoch 0:  96%|    | 479/500 [00:01<00:00, 302.90it/s, loss=0.757, v_num=2]\u001b[A\n",
      "Epoch 0:  96%|    | 480/500 [00:01<00:00, 302.88it/s, loss=0.757, v_num=2]\u001b[A\n",
      "Epoch 0:  96%|    | 481/500 [00:01<00:00, 302.92it/s, loss=0.757, v_num=2]\u001b[A\n",
      "Epoch 0:  96%|   | 482/500 [00:01<00:00, 303.03it/s, loss=0.757, v_num=2]\u001b[A\n",
      "Epoch 0:  97%|   | 483/500 [00:01<00:00, 303.09it/s, loss=0.757, v_num=2]\u001b[A\n",
      "Epoch 0:  97%|   | 484/500 [00:01<00:00, 303.09it/s, loss=0.757, v_num=2]\u001b[A\n",
      "Epoch 0:  97%|   | 485/500 [00:01<00:00, 303.18it/s, loss=0.757, v_num=2]\u001b[A\n",
      "Epoch 0:  97%|   | 486/500 [00:01<00:00, 303.23it/s, loss=0.757, v_num=2]\u001b[A\n",
      "Epoch 0:  97%|  | 487/500 [00:01<00:00, 303.34it/s, loss=0.757, v_num=2]\u001b[A\n",
      "Epoch 0:  98%|  | 488/500 [00:01<00:00, 303.31it/s, loss=0.757, v_num=2]\u001b[A\n",
      "Epoch 0:  98%|  | 489/500 [00:01<00:00, 303.40it/s, loss=0.757, v_num=2]\u001b[A\n",
      "Epoch 0:  98%|  | 490/500 [00:01<00:00, 303.45it/s, loss=0.757, v_num=2]\u001b[A\n",
      "Epoch 0:  98%|  | 491/500 [00:01<00:00, 303.47it/s, loss=0.757, v_num=2]\u001b[A\n",
      "Epoch 0:  98%| | 492/500 [00:01<00:00, 303.40it/s, loss=0.757, v_num=2]\u001b[A\n",
      "Epoch 0:  99%| | 493/500 [00:01<00:00, 303.35it/s, loss=0.757, v_num=2]\u001b[A\n",
      "Epoch 0:  99%| | 494/500 [00:01<00:00, 303.42it/s, loss=0.757, v_num=2]\u001b[A\n",
      "Epoch 0:  99%| | 495/500 [00:01<00:00, 303.50it/s, loss=0.757, v_num=2]\u001b[A\n",
      "Epoch 0:  99%|| 496/500 [00:01<00:00, 303.61it/s, loss=0.757, v_num=2]\u001b[A\n",
      "Epoch 0:  99%|| 497/500 [00:01<00:00, 303.73it/s, loss=0.757, v_num=2]\u001b[A\n",
      "Epoch 0: 100%|| 498/500 [00:01<00:00, 303.90it/s, loss=0.757, v_num=2]\u001b[A\n",
      "Epoch 0: 100%|| 499/500 [00:01<00:00, 304.05it/s, loss=0.757, v_num=2]\u001b[A\n",
      "Epoch 0: 100%|| 500/500 [00:01<00:00, 303.10it/s, loss=0.757, v_num=2, val_loss=0.767, val_acc=0.423]\u001b[A\n",
      "Epoch 1:  90%|     | 450/500 [00:01<00:00, 295.96it/s, loss=0.604, v_num=2, val_loss=0.767, val_acc=0.423, train_acc=0.426]\u001b[A\n",
      "Validation: 0it [00:00, ?it/s]\u001b[A\n",
      "Validation:   0%|                                                                                                                                        | 0/50 [00:00<?, ?it/s]\u001b[A\n",
      "Validation DataLoader 0:   0%|                                                                                                                           | 0/50 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 1:  90%|     | 451/500 [00:01<00:00, 293.50it/s, loss=0.604, v_num=2, val_loss=0.767, val_acc=0.423, train_acc=0.426]\u001b[A\n",
      "Epoch 1:  90%|     | 452/500 [00:01<00:00, 293.52it/s, loss=0.604, v_num=2, val_loss=0.767, val_acc=0.423, train_acc=0.426]\u001b[A\n",
      "Epoch 1:  91%|     | 453/500 [00:01<00:00, 293.52it/s, loss=0.604, v_num=2, val_loss=0.767, val_acc=0.423, train_acc=0.426]\u001b[A\n",
      "Epoch 1:  91%|     | 454/500 [00:01<00:00, 293.57it/s, loss=0.604, v_num=2, val_loss=0.767, val_acc=0.423, train_acc=0.426]\u001b[A\n",
      "Epoch 1:  91%|     | 455/500 [00:01<00:00, 293.58it/s, loss=0.604, v_num=2, val_loss=0.767, val_acc=0.423, train_acc=0.426]\u001b[A\n",
      "Epoch 1:  91%|     | 456/500 [00:01<00:00, 293.43it/s, loss=0.604, v_num=2, val_loss=0.767, val_acc=0.423, train_acc=0.426]\u001b[A\n",
      "Epoch 1:  91%|     | 457/500 [00:01<00:00, 293.48it/s, loss=0.604, v_num=2, val_loss=0.767, val_acc=0.423, train_acc=0.426]\u001b[A\n",
      "Epoch 1:  92%|    | 458/500 [00:01<00:00, 293.44it/s, loss=0.604, v_num=2, val_loss=0.767, val_acc=0.423, train_acc=0.426]\u001b[A\n",
      "Epoch 1:  92%|    | 459/500 [00:01<00:00, 293.45it/s, loss=0.604, v_num=2, val_loss=0.767, val_acc=0.423, train_acc=0.426]\u001b[A\n",
      "Epoch 1:  92%|    | 460/500 [00:01<00:00, 293.52it/s, loss=0.604, v_num=2, val_loss=0.767, val_acc=0.423, train_acc=0.426]\u001b[A\n",
      "Epoch 1:  92%|    | 461/500 [00:01<00:00, 293.51it/s, loss=0.604, v_num=2, val_loss=0.767, val_acc=0.423, train_acc=0.426]\u001b[A\n",
      "Epoch 1:  92%|    | 462/500 [00:01<00:00, 293.51it/s, loss=0.604, v_num=2, val_loss=0.767, val_acc=0.423, train_acc=0.426]\u001b[A\n",
      "Epoch 1:  93%|    | 463/500 [00:01<00:00, 293.52it/s, loss=0.604, v_num=2, val_loss=0.767, val_acc=0.423, train_acc=0.426]\u001b[A\n",
      "Epoch 1:  93%|    | 464/500 [00:01<00:00, 293.46it/s, loss=0.604, v_num=2, val_loss=0.767, val_acc=0.423, train_acc=0.426]\u001b[A\n",
      "Epoch 1:  93%|    | 465/500 [00:01<00:00, 293.49it/s, loss=0.604, v_num=2, val_loss=0.767, val_acc=0.423, train_acc=0.426]\u001b[A\n",
      "Epoch 1:  93%|    | 466/500 [00:01<00:00, 293.50it/s, loss=0.604, v_num=2, val_loss=0.767, val_acc=0.423, train_acc=0.426]\u001b[A\n",
      "Epoch 1:  93%|   | 467/500 [00:01<00:00, 293.56it/s, loss=0.604, v_num=2, val_loss=0.767, val_acc=0.423, train_acc=0.426]\u001b[A\n",
      "Epoch 1:  94%|   | 468/500 [00:01<00:00, 293.67it/s, loss=0.604, v_num=2, val_loss=0.767, val_acc=0.423, train_acc=0.426]\u001b[A\n",
      "Epoch 1:  94%|   | 469/500 [00:01<00:00, 293.75it/s, loss=0.604, v_num=2, val_loss=0.767, val_acc=0.423, train_acc=0.426]\u001b[A\n",
      "Epoch 1:  94%|   | 470/500 [00:01<00:00, 293.87it/s, loss=0.604, v_num=2, val_loss=0.767, val_acc=0.423, train_acc=0.426]\u001b[A\n",
      "Epoch 1:  94%|   | 471/500 [00:01<00:00, 293.92it/s, loss=0.604, v_num=2, val_loss=0.767, val_acc=0.423, train_acc=0.426]\u001b[A\n",
      "Epoch 1:  94%|   | 472/500 [00:01<00:00, 294.02it/s, loss=0.604, v_num=2, val_loss=0.767, val_acc=0.423, train_acc=0.426]\u001b[A\n",
      "Epoch 1:  95%|   | 473/500 [00:01<00:00, 294.16it/s, loss=0.604, v_num=2, val_loss=0.767, val_acc=0.423, train_acc=0.426]\u001b[A\n",
      "Epoch 1:  95%|   | 474/500 [00:01<00:00, 294.18it/s, loss=0.604, v_num=2, val_loss=0.767, val_acc=0.423, train_acc=0.426]\u001b[A\n",
      "Epoch 1:  95%|   | 475/500 [00:01<00:00, 294.12it/s, loss=0.604, v_num=2, val_loss=0.767, val_acc=0.423, train_acc=0.426]\u001b[A\n",
      "Epoch 1:  95%|  | 476/500 [00:01<00:00, 294.17it/s, loss=0.604, v_num=2, val_loss=0.767, val_acc=0.423, train_acc=0.426]\u001b[A\n",
      "Epoch 1:  95%|  | 477/500 [00:01<00:00, 294.16it/s, loss=0.604, v_num=2, val_loss=0.767, val_acc=0.423, train_acc=0.426]\u001b[A\n",
      "Epoch 1:  96%|  | 478/500 [00:01<00:00, 294.14it/s, loss=0.604, v_num=2, val_loss=0.767, val_acc=0.423, train_acc=0.426]\u001b[A\n",
      "Epoch 1:  96%|  | 479/500 [00:01<00:00, 294.15it/s, loss=0.604, v_num=2, val_loss=0.767, val_acc=0.423, train_acc=0.426]\u001b[A\n",
      "Epoch 1:  96%|  | 480/500 [00:01<00:00, 294.22it/s, loss=0.604, v_num=2, val_loss=0.767, val_acc=0.423, train_acc=0.426]\u001b[A\n",
      "Epoch 1:  96%|  | 481/500 [00:01<00:00, 294.35it/s, loss=0.604, v_num=2, val_loss=0.767, val_acc=0.423, train_acc=0.426]\u001b[A\n",
      "Epoch 1:  96%|  | 482/500 [00:01<00:00, 294.45it/s, loss=0.604, v_num=2, val_loss=0.767, val_acc=0.423, train_acc=0.426]\u001b[A\n",
      "Epoch 1:  97%|  | 483/500 [00:01<00:00, 294.53it/s, loss=0.604, v_num=2, val_loss=0.767, val_acc=0.423, train_acc=0.426]\u001b[A\n",
      "Epoch 1:  97%| | 484/500 [00:01<00:00, 294.50it/s, loss=0.604, v_num=2, val_loss=0.767, val_acc=0.423, train_acc=0.426]\u001b[A\n",
      "Epoch 1:  97%| | 485/500 [00:01<00:00, 294.48it/s, loss=0.604, v_num=2, val_loss=0.767, val_acc=0.423, train_acc=0.426]\u001b[A\n",
      "Epoch 1:  97%| | 486/500 [00:01<00:00, 294.58it/s, loss=0.604, v_num=2, val_loss=0.767, val_acc=0.423, train_acc=0.426]\u001b[A\n",
      "Epoch 1:  97%| | 487/500 [00:01<00:00, 294.68it/s, loss=0.604, v_num=2, val_loss=0.767, val_acc=0.423, train_acc=0.426]\u001b[A\n",
      "Epoch 1:  98%| | 488/500 [00:01<00:00, 294.80it/s, loss=0.604, v_num=2, val_loss=0.767, val_acc=0.423, train_acc=0.426]\u001b[A\n",
      "Epoch 1:  98%| | 489/500 [00:01<00:00, 294.78it/s, loss=0.604, v_num=2, val_loss=0.767, val_acc=0.423, train_acc=0.426]\u001b[A\n",
      "Epoch 1:  98%| | 490/500 [00:01<00:00, 294.82it/s, loss=0.604, v_num=2, val_loss=0.767, val_acc=0.423, train_acc=0.426]\u001b[A\n",
      "Epoch 1:  98%| | 491/500 [00:01<00:00, 294.76it/s, loss=0.604, v_num=2, val_loss=0.767, val_acc=0.423, train_acc=0.426]\u001b[A\n",
      "Epoch 1:  98%| | 492/500 [00:01<00:00, 294.75it/s, loss=0.604, v_num=2, val_loss=0.767, val_acc=0.423, train_acc=0.426]\u001b[A\n",
      "Epoch 1:  99%|| 493/500 [00:01<00:00, 294.89it/s, loss=0.604, v_num=2, val_loss=0.767, val_acc=0.423, train_acc=0.426]\u001b[A\n",
      "Epoch 1:  99%|| 494/500 [00:01<00:00, 295.02it/s, loss=0.604, v_num=2, val_loss=0.767, val_acc=0.423, train_acc=0.426]\u001b[A\n",
      "Epoch 1:  99%|| 495/500 [00:01<00:00, 295.05it/s, loss=0.604, v_num=2, val_loss=0.767, val_acc=0.423, train_acc=0.426]\u001b[A\n",
      "Epoch 1:  99%|| 496/500 [00:01<00:00, 294.99it/s, loss=0.604, v_num=2, val_loss=0.767, val_acc=0.423, train_acc=0.426]\u001b[A\n",
      "Epoch 1:  99%|| 497/500 [00:01<00:00, 295.00it/s, loss=0.604, v_num=2, val_loss=0.767, val_acc=0.423, train_acc=0.426]\u001b[A\n",
      "Epoch 1: 100%|| 498/500 [00:01<00:00, 295.02it/s, loss=0.604, v_num=2, val_loss=0.767, val_acc=0.423, train_acc=0.426]\u001b[A\n",
      "Epoch 1: 100%|| 499/500 [00:01<00:00, 295.02it/s, loss=0.604, v_num=2, val_loss=0.767, val_acc=0.423, train_acc=0.426]\u001b[A\n",
      "Epoch 1: 100%|| 500/500 [00:01<00:00, 293.54it/s, loss=0.604, v_num=2, val_loss=0.609, val_acc=0.673, train_acc=0.426]\u001b[A\n",
      "Epoch 2:  90%|     | 450/500 [00:01<00:00, 266.43it/s, loss=0.554, v_num=2, val_loss=0.609, val_acc=0.673, train_acc=0.633]\u001b[A\n",
      "Validation: 0it [00:00, ?it/s]\u001b[A\n",
      "Validation:   0%|                                                                                                                                        | 0/50 [00:00<?, ?it/s]\u001b[A\n",
      "Validation DataLoader 0:   0%|                                                                                                                           | 0/50 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 2:  90%|     | 451/500 [00:01<00:00, 264.95it/s, loss=0.554, v_num=2, val_loss=0.609, val_acc=0.673, train_acc=0.633]\u001b[A\n",
      "Epoch 2:  90%|     | 452/500 [00:01<00:00, 265.05it/s, loss=0.554, v_num=2, val_loss=0.609, val_acc=0.673, train_acc=0.633]\u001b[A\n",
      "Epoch 2:  91%|     | 453/500 [00:01<00:00, 265.09it/s, loss=0.554, v_num=2, val_loss=0.609, val_acc=0.673, train_acc=0.633]\u001b[A\n",
      "Epoch 2:  91%|     | 454/500 [00:01<00:00, 265.14it/s, loss=0.554, v_num=2, val_loss=0.609, val_acc=0.673, train_acc=0.633]\u001b[A\n",
      "Epoch 2:  91%|     | 455/500 [00:01<00:00, 265.26it/s, loss=0.554, v_num=2, val_loss=0.609, val_acc=0.673, train_acc=0.633]\u001b[A\n",
      "Epoch 2:  91%|     | 456/500 [00:01<00:00, 265.39it/s, loss=0.554, v_num=2, val_loss=0.609, val_acc=0.673, train_acc=0.633]\u001b[A\n",
      "Epoch 2:  91%|     | 457/500 [00:01<00:00, 265.46it/s, loss=0.554, v_num=2, val_loss=0.609, val_acc=0.673, train_acc=0.633]\u001b[A\n",
      "Epoch 2:  92%|    | 458/500 [00:01<00:00, 265.67it/s, loss=0.554, v_num=2, val_loss=0.609, val_acc=0.673, train_acc=0.633]\u001b[A\n",
      "Epoch 2:  92%|    | 459/500 [00:01<00:00, 265.68it/s, loss=0.554, v_num=2, val_loss=0.609, val_acc=0.673, train_acc=0.633]\u001b[A\n",
      "Epoch 2:  92%|    | 460/500 [00:01<00:00, 265.76it/s, loss=0.554, v_num=2, val_loss=0.609, val_acc=0.673, train_acc=0.633]\u001b[A\n",
      "Epoch 2:  92%|    | 461/500 [00:01<00:00, 265.85it/s, loss=0.554, v_num=2, val_loss=0.609, val_acc=0.673, train_acc=0.633]\u001b[A\n",
      "Epoch 2:  92%|    | 462/500 [00:01<00:00, 265.87it/s, loss=0.554, v_num=2, val_loss=0.609, val_acc=0.673, train_acc=0.633]\u001b[A\n",
      "Epoch 2:  93%|    | 463/500 [00:01<00:00, 265.90it/s, loss=0.554, v_num=2, val_loss=0.609, val_acc=0.673, train_acc=0.633]\u001b[A\n",
      "Epoch 2:  93%|    | 464/500 [00:01<00:00, 265.93it/s, loss=0.554, v_num=2, val_loss=0.609, val_acc=0.673, train_acc=0.633]\u001b[A\n",
      "Epoch 2:  93%|    | 465/500 [00:01<00:00, 266.04it/s, loss=0.554, v_num=2, val_loss=0.609, val_acc=0.673, train_acc=0.633]\u001b[A\n",
      "Epoch 2:  93%|    | 466/500 [00:01<00:00, 266.16it/s, loss=0.554, v_num=2, val_loss=0.609, val_acc=0.673, train_acc=0.633]\u001b[A\n",
      "Epoch 2:  93%|   | 467/500 [00:01<00:00, 266.26it/s, loss=0.554, v_num=2, val_loss=0.609, val_acc=0.673, train_acc=0.633]\u001b[A\n",
      "Epoch 2:  94%|   | 468/500 [00:01<00:00, 266.36it/s, loss=0.554, v_num=2, val_loss=0.609, val_acc=0.673, train_acc=0.633]\u001b[A\n",
      "Epoch 2:  94%|   | 469/500 [00:01<00:00, 266.42it/s, loss=0.554, v_num=2, val_loss=0.609, val_acc=0.673, train_acc=0.633]\u001b[A\n",
      "Epoch 2:  94%|   | 470/500 [00:01<00:00, 266.50it/s, loss=0.554, v_num=2, val_loss=0.609, val_acc=0.673, train_acc=0.633]\u001b[A\n",
      "Epoch 2:  94%|   | 471/500 [00:01<00:00, 266.57it/s, loss=0.554, v_num=2, val_loss=0.609, val_acc=0.673, train_acc=0.633]\u001b[A\n",
      "Epoch 2:  94%|   | 472/500 [00:01<00:00, 266.61it/s, loss=0.554, v_num=2, val_loss=0.609, val_acc=0.673, train_acc=0.633]\u001b[A\n",
      "Epoch 2:  95%|   | 473/500 [00:01<00:00, 266.75it/s, loss=0.554, v_num=2, val_loss=0.609, val_acc=0.673, train_acc=0.633]\u001b[A\n",
      "Epoch 2:  95%|   | 474/500 [00:01<00:00, 266.87it/s, loss=0.554, v_num=2, val_loss=0.609, val_acc=0.673, train_acc=0.633]\u001b[A\n",
      "Epoch 2:  95%|   | 475/500 [00:01<00:00, 266.94it/s, loss=0.554, v_num=2, val_loss=0.609, val_acc=0.673, train_acc=0.633]\u001b[A\n",
      "Epoch 2:  95%|  | 476/500 [00:01<00:00, 267.06it/s, loss=0.554, v_num=2, val_loss=0.609, val_acc=0.673, train_acc=0.633]\u001b[A\n",
      "Epoch 2:  95%|  | 477/500 [00:01<00:00, 267.16it/s, loss=0.554, v_num=2, val_loss=0.609, val_acc=0.673, train_acc=0.633]\u001b[A\n",
      "Epoch 2:  96%|  | 478/500 [00:01<00:00, 267.22it/s, loss=0.554, v_num=2, val_loss=0.609, val_acc=0.673, train_acc=0.633]\u001b[A\n",
      "Epoch 2:  96%|  | 479/500 [00:01<00:00, 267.26it/s, loss=0.554, v_num=2, val_loss=0.609, val_acc=0.673, train_acc=0.633]\u001b[A\n",
      "Epoch 2:  96%|  | 480/500 [00:01<00:00, 267.33it/s, loss=0.554, v_num=2, val_loss=0.609, val_acc=0.673, train_acc=0.633]\u001b[A\n",
      "Epoch 2:  96%|  | 481/500 [00:01<00:00, 267.39it/s, loss=0.554, v_num=2, val_loss=0.609, val_acc=0.673, train_acc=0.633]\u001b[A\n",
      "Epoch 2:  96%|  | 482/500 [00:01<00:00, 267.44it/s, loss=0.554, v_num=2, val_loss=0.609, val_acc=0.673, train_acc=0.633]\u001b[A\n",
      "Epoch 2:  97%|  | 483/500 [00:01<00:00, 267.44it/s, loss=0.554, v_num=2, val_loss=0.609, val_acc=0.673, train_acc=0.633]\u001b[A\n",
      "Epoch 2:  97%| | 484/500 [00:01<00:00, 267.53it/s, loss=0.554, v_num=2, val_loss=0.609, val_acc=0.673, train_acc=0.633]\u001b[A\n",
      "Epoch 2:  97%| | 485/500 [00:01<00:00, 267.58it/s, loss=0.554, v_num=2, val_loss=0.609, val_acc=0.673, train_acc=0.633]\u001b[A\n",
      "Epoch 2:  97%| | 486/500 [00:01<00:00, 267.63it/s, loss=0.554, v_num=2, val_loss=0.609, val_acc=0.673, train_acc=0.633]\u001b[A\n",
      "Epoch 2:  97%| | 487/500 [00:01<00:00, 267.74it/s, loss=0.554, v_num=2, val_loss=0.609, val_acc=0.673, train_acc=0.633]\u001b[A\n",
      "Epoch 2:  98%| | 488/500 [00:01<00:00, 267.80it/s, loss=0.554, v_num=2, val_loss=0.609, val_acc=0.673, train_acc=0.633]\u001b[A\n",
      "Epoch 2:  98%| | 489/500 [00:01<00:00, 267.95it/s, loss=0.554, v_num=2, val_loss=0.609, val_acc=0.673, train_acc=0.633]\u001b[A\n",
      "Epoch 2:  98%| | 490/500 [00:01<00:00, 268.03it/s, loss=0.554, v_num=2, val_loss=0.609, val_acc=0.673, train_acc=0.633]\u001b[A\n",
      "Epoch 2:  98%| | 491/500 [00:01<00:00, 268.14it/s, loss=0.554, v_num=2, val_loss=0.609, val_acc=0.673, train_acc=0.633]\u001b[A\n",
      "Epoch 2:  98%| | 492/500 [00:01<00:00, 268.23it/s, loss=0.554, v_num=2, val_loss=0.609, val_acc=0.673, train_acc=0.633]\u001b[A\n",
      "Epoch 2:  99%|| 493/500 [00:01<00:00, 268.33it/s, loss=0.554, v_num=2, val_loss=0.609, val_acc=0.673, train_acc=0.633]\u001b[A\n",
      "Epoch 2:  99%|| 494/500 [00:01<00:00, 268.43it/s, loss=0.554, v_num=2, val_loss=0.609, val_acc=0.673, train_acc=0.633]\u001b[A\n",
      "Epoch 2:  99%|| 495/500 [00:01<00:00, 268.50it/s, loss=0.554, v_num=2, val_loss=0.609, val_acc=0.673, train_acc=0.633]\u001b[A\n",
      "Epoch 2:  99%|| 496/500 [00:01<00:00, 268.43it/s, loss=0.554, v_num=2, val_loss=0.609, val_acc=0.673, train_acc=0.633]\u001b[A\n",
      "Epoch 2:  99%|| 497/500 [00:01<00:00, 268.55it/s, loss=0.554, v_num=2, val_loss=0.609, val_acc=0.673, train_acc=0.633]\u001b[A\n",
      "Epoch 2: 100%|| 498/500 [00:01<00:00, 268.63it/s, loss=0.554, v_num=2, val_loss=0.609, val_acc=0.673, train_acc=0.633]\u001b[A\n",
      "Epoch 2: 100%|| 499/500 [00:01<00:00, 268.75it/s, loss=0.554, v_num=2, val_loss=0.609, val_acc=0.673, train_acc=0.633]\u001b[A\n",
      "Epoch 2: 100%|| 500/500 [00:01<00:00, 267.28it/s, loss=0.554, v_num=2, val_loss=0.558, val_acc=0.711, train_acc=0.633]\u001b[A\n",
      "Epoch 3:  90%|     | 450/500 [00:01<00:00, 280.70it/s, loss=0.513, v_num=2, val_loss=0.558, val_acc=0.711, train_acc=0.711]\u001b[A\n",
      "Validation: 0it [00:00, ?it/s]\u001b[A\n",
      "Validation:   0%|                                                                                                                                        | 0/50 [00:00<?, ?it/s]\u001b[A\n",
      "Validation DataLoader 0:   0%|                                                                                                                           | 0/50 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 3:  90%|     | 451/500 [00:01<00:00, 277.50it/s, loss=0.513, v_num=2, val_loss=0.558, val_acc=0.711, train_acc=0.711]\u001b[A\n",
      "Epoch 3:  90%|     | 452/500 [00:01<00:00, 277.53it/s, loss=0.513, v_num=2, val_loss=0.558, val_acc=0.711, train_acc=0.711]\u001b[A\n",
      "Epoch 3:  91%|     | 453/500 [00:01<00:00, 277.54it/s, loss=0.513, v_num=2, val_loss=0.558, val_acc=0.711, train_acc=0.711]\u001b[A\n",
      "Epoch 3:  91%|     | 454/500 [00:01<00:00, 277.49it/s, loss=0.513, v_num=2, val_loss=0.558, val_acc=0.711, train_acc=0.711]\u001b[A\n",
      "Epoch 3:  91%|     | 455/500 [00:01<00:00, 277.55it/s, loss=0.513, v_num=2, val_loss=0.558, val_acc=0.711, train_acc=0.711]\u001b[A\n",
      "Epoch 3:  91%|     | 456/500 [00:01<00:00, 277.50it/s, loss=0.513, v_num=2, val_loss=0.558, val_acc=0.711, train_acc=0.711]\u001b[A\n",
      "Epoch 3:  91%|     | 457/500 [00:01<00:00, 277.55it/s, loss=0.513, v_num=2, val_loss=0.558, val_acc=0.711, train_acc=0.711]\u001b[A\n",
      "Epoch 3:  92%|    | 458/500 [00:01<00:00, 277.50it/s, loss=0.513, v_num=2, val_loss=0.558, val_acc=0.711, train_acc=0.711]\u001b[A\n",
      "Epoch 3:  92%|    | 459/500 [00:01<00:00, 277.48it/s, loss=0.513, v_num=2, val_loss=0.558, val_acc=0.711, train_acc=0.711]\u001b[A\n",
      "Epoch 3:  92%|    | 460/500 [00:01<00:00, 277.53it/s, loss=0.513, v_num=2, val_loss=0.558, val_acc=0.711, train_acc=0.711]\u001b[A\n",
      "Epoch 3:  92%|    | 461/500 [00:01<00:00, 277.58it/s, loss=0.513, v_num=2, val_loss=0.558, val_acc=0.711, train_acc=0.711]\u001b[A\n",
      "Epoch 3:  92%|    | 462/500 [00:01<00:00, 277.64it/s, loss=0.513, v_num=2, val_loss=0.558, val_acc=0.711, train_acc=0.711]\u001b[A\n",
      "Epoch 3:  93%|    | 463/500 [00:01<00:00, 277.65it/s, loss=0.513, v_num=2, val_loss=0.558, val_acc=0.711, train_acc=0.711]\u001b[A\n",
      "Epoch 3:  93%|    | 464/500 [00:01<00:00, 277.70it/s, loss=0.513, v_num=2, val_loss=0.558, val_acc=0.711, train_acc=0.711]\u001b[A\n",
      "Epoch 3:  93%|    | 465/500 [00:01<00:00, 277.85it/s, loss=0.513, v_num=2, val_loss=0.558, val_acc=0.711, train_acc=0.711]\u001b[A\n",
      "Epoch 3:  93%|    | 466/500 [00:01<00:00, 277.95it/s, loss=0.513, v_num=2, val_loss=0.558, val_acc=0.711, train_acc=0.711]\u001b[A\n",
      "Epoch 3:  93%|   | 467/500 [00:01<00:00, 277.93it/s, loss=0.513, v_num=2, val_loss=0.558, val_acc=0.711, train_acc=0.711]\u001b[A\n",
      "Epoch 3:  94%|   | 468/500 [00:01<00:00, 278.00it/s, loss=0.513, v_num=2, val_loss=0.558, val_acc=0.711, train_acc=0.711]\u001b[A\n",
      "Epoch 3:  94%|   | 469/500 [00:01<00:00, 278.10it/s, loss=0.513, v_num=2, val_loss=0.558, val_acc=0.711, train_acc=0.711]\u001b[A\n",
      "Epoch 3:  94%|   | 470/500 [00:01<00:00, 278.13it/s, loss=0.513, v_num=2, val_loss=0.558, val_acc=0.711, train_acc=0.711]\u001b[A\n",
      "Epoch 3:  94%|   | 471/500 [00:01<00:00, 278.18it/s, loss=0.513, v_num=2, val_loss=0.558, val_acc=0.711, train_acc=0.711]\u001b[A\n",
      "Epoch 3:  94%|   | 472/500 [00:01<00:00, 278.25it/s, loss=0.513, v_num=2, val_loss=0.558, val_acc=0.711, train_acc=0.711]\u001b[A\n",
      "Epoch 3:  95%|   | 473/500 [00:01<00:00, 278.35it/s, loss=0.513, v_num=2, val_loss=0.558, val_acc=0.711, train_acc=0.711]\u001b[A\n",
      "Epoch 3:  95%|   | 474/500 [00:01<00:00, 278.45it/s, loss=0.513, v_num=2, val_loss=0.558, val_acc=0.711, train_acc=0.711]\u001b[A\n",
      "Epoch 3:  95%|   | 475/500 [00:01<00:00, 278.54it/s, loss=0.513, v_num=2, val_loss=0.558, val_acc=0.711, train_acc=0.711]\u001b[A\n",
      "Epoch 3:  95%|  | 476/500 [00:01<00:00, 278.64it/s, loss=0.513, v_num=2, val_loss=0.558, val_acc=0.711, train_acc=0.711]\u001b[A\n",
      "Epoch 3:  95%|  | 477/500 [00:01<00:00, 278.78it/s, loss=0.513, v_num=2, val_loss=0.558, val_acc=0.711, train_acc=0.711]\u001b[A\n",
      "Epoch 3:  96%|  | 478/500 [00:01<00:00, 278.89it/s, loss=0.513, v_num=2, val_loss=0.558, val_acc=0.711, train_acc=0.711]\u001b[A\n",
      "Epoch 3:  96%|  | 479/500 [00:01<00:00, 278.98it/s, loss=0.513, v_num=2, val_loss=0.558, val_acc=0.711, train_acc=0.711]\u001b[A\n",
      "Epoch 3:  96%|  | 480/500 [00:01<00:00, 278.97it/s, loss=0.513, v_num=2, val_loss=0.558, val_acc=0.711, train_acc=0.711]\u001b[A\n",
      "Epoch 3:  96%|  | 481/500 [00:01<00:00, 278.99it/s, loss=0.513, v_num=2, val_loss=0.558, val_acc=0.711, train_acc=0.711]\u001b[A\n",
      "Epoch 3:  96%|  | 482/500 [00:01<00:00, 279.06it/s, loss=0.513, v_num=2, val_loss=0.558, val_acc=0.711, train_acc=0.711]\u001b[A\n",
      "Epoch 3:  97%|  | 483/500 [00:01<00:00, 279.10it/s, loss=0.513, v_num=2, val_loss=0.558, val_acc=0.711, train_acc=0.711]\u001b[A\n",
      "Epoch 3:  97%| | 484/500 [00:01<00:00, 279.22it/s, loss=0.513, v_num=2, val_loss=0.558, val_acc=0.711, train_acc=0.711]\u001b[A\n",
      "Epoch 3:  97%| | 485/500 [00:01<00:00, 279.23it/s, loss=0.513, v_num=2, val_loss=0.558, val_acc=0.711, train_acc=0.711]\u001b[A\n",
      "Epoch 3:  97%| | 486/500 [00:01<00:00, 279.16it/s, loss=0.513, v_num=2, val_loss=0.558, val_acc=0.711, train_acc=0.711]\u001b[A\n",
      "Epoch 3:  97%| | 487/500 [00:01<00:00, 279.16it/s, loss=0.513, v_num=2, val_loss=0.558, val_acc=0.711, train_acc=0.711]\u001b[A\n",
      "Epoch 3:  98%| | 488/500 [00:01<00:00, 279.14it/s, loss=0.513, v_num=2, val_loss=0.558, val_acc=0.711, train_acc=0.711]\u001b[A\n",
      "Epoch 3:  98%| | 489/500 [00:01<00:00, 279.10it/s, loss=0.513, v_num=2, val_loss=0.558, val_acc=0.711, train_acc=0.711]\u001b[A\n",
      "Epoch 3:  98%| | 490/500 [00:01<00:00, 279.15it/s, loss=0.513, v_num=2, val_loss=0.558, val_acc=0.711, train_acc=0.711]\u001b[A\n",
      "Epoch 3:  98%| | 491/500 [00:01<00:00, 279.17it/s, loss=0.513, v_num=2, val_loss=0.558, val_acc=0.711, train_acc=0.711]\u001b[A\n",
      "Epoch 3:  98%| | 492/500 [00:01<00:00, 279.27it/s, loss=0.513, v_num=2, val_loss=0.558, val_acc=0.711, train_acc=0.711]\u001b[A\n",
      "Epoch 3:  99%|| 493/500 [00:01<00:00, 279.38it/s, loss=0.513, v_num=2, val_loss=0.558, val_acc=0.711, train_acc=0.711]\u001b[A\n",
      "Epoch 3:  99%|| 494/500 [00:01<00:00, 279.49it/s, loss=0.513, v_num=2, val_loss=0.558, val_acc=0.711, train_acc=0.711]\u001b[A\n",
      "Epoch 3:  99%|| 495/500 [00:01<00:00, 279.63it/s, loss=0.513, v_num=2, val_loss=0.558, val_acc=0.711, train_acc=0.711]\u001b[A\n",
      "Epoch 3:  99%|| 496/500 [00:01<00:00, 279.67it/s, loss=0.513, v_num=2, val_loss=0.558, val_acc=0.711, train_acc=0.711]\u001b[A\n",
      "Epoch 3:  99%|| 497/500 [00:01<00:00, 279.86it/s, loss=0.513, v_num=2, val_loss=0.558, val_acc=0.711, train_acc=0.711]\u001b[A\n",
      "Epoch 3: 100%|| 498/500 [00:01<00:00, 279.92it/s, loss=0.513, v_num=2, val_loss=0.558, val_acc=0.711, train_acc=0.711]\u001b[A\n",
      "Epoch 3: 100%|| 499/500 [00:01<00:00, 280.00it/s, loss=0.513, v_num=2, val_loss=0.558, val_acc=0.711, train_acc=0.711]\u001b[A\n",
      "Epoch 3: 100%|| 500/500 [00:01<00:00, 277.66it/s, loss=0.513, v_num=2, val_loss=0.520, val_acc=0.745, train_acc=0.711]\u001b[A\n",
      "Epoch 4:  90%|     | 450/500 [00:01<00:00, 290.05it/s, loss=0.481, v_num=2, val_loss=0.520, val_acc=0.745, train_acc=0.741]\u001b[A\n",
      "Validation: 0it [00:00, ?it/s]\u001b[A\n",
      "Validation:   0%|                                                                                                                                        | 0/50 [00:00<?, ?it/s]\u001b[A\n",
      "Validation DataLoader 0:   0%|                                                                                                                           | 0/50 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 4:  90%|     | 451/500 [00:01<00:00, 288.24it/s, loss=0.481, v_num=2, val_loss=0.520, val_acc=0.745, train_acc=0.741]\u001b[A\n",
      "Epoch 4:  90%|     | 452/500 [00:01<00:00, 288.08it/s, loss=0.481, v_num=2, val_loss=0.520, val_acc=0.745, train_acc=0.741]\u001b[A\n",
      "Epoch 4:  91%|     | 453/500 [00:01<00:00, 288.14it/s, loss=0.481, v_num=2, val_loss=0.520, val_acc=0.745, train_acc=0.741]\u001b[A\n",
      "Epoch 4:  91%|     | 454/500 [00:01<00:00, 288.17it/s, loss=0.481, v_num=2, val_loss=0.520, val_acc=0.745, train_acc=0.741]\u001b[A\n",
      "Epoch 4:  91%|     | 455/500 [00:01<00:00, 288.21it/s, loss=0.481, v_num=2, val_loss=0.520, val_acc=0.745, train_acc=0.741]\u001b[A\n",
      "Epoch 4:  91%|     | 456/500 [00:01<00:00, 288.27it/s, loss=0.481, v_num=2, val_loss=0.520, val_acc=0.745, train_acc=0.741]\u001b[A\n",
      "Epoch 4:  91%|     | 457/500 [00:01<00:00, 288.20it/s, loss=0.481, v_num=2, val_loss=0.520, val_acc=0.745, train_acc=0.741]\u001b[A\n",
      "Epoch 4:  92%|    | 458/500 [00:01<00:00, 288.25it/s, loss=0.481, v_num=2, val_loss=0.520, val_acc=0.745, train_acc=0.741]\u001b[A\n",
      "Epoch 4:  92%|    | 459/500 [00:01<00:00, 288.22it/s, loss=0.481, v_num=2, val_loss=0.520, val_acc=0.745, train_acc=0.741]\u001b[A\n",
      "Epoch 4:  92%|    | 460/500 [00:01<00:00, 288.23it/s, loss=0.481, v_num=2, val_loss=0.520, val_acc=0.745, train_acc=0.741]\u001b[A\n",
      "Epoch 4:  92%|    | 461/500 [00:01<00:00, 288.23it/s, loss=0.481, v_num=2, val_loss=0.520, val_acc=0.745, train_acc=0.741]\u001b[A\n",
      "Epoch 4:  92%|    | 462/500 [00:01<00:00, 288.31it/s, loss=0.481, v_num=2, val_loss=0.520, val_acc=0.745, train_acc=0.741]\u001b[A\n",
      "Epoch 4:  93%|    | 463/500 [00:01<00:00, 288.32it/s, loss=0.481, v_num=2, val_loss=0.520, val_acc=0.745, train_acc=0.741]\u001b[A\n",
      "Epoch 4:  93%|    | 464/500 [00:01<00:00, 288.43it/s, loss=0.481, v_num=2, val_loss=0.520, val_acc=0.745, train_acc=0.741]\u001b[A\n",
      "Epoch 4:  93%|    | 465/500 [00:01<00:00, 288.47it/s, loss=0.481, v_num=2, val_loss=0.520, val_acc=0.745, train_acc=0.741]\u001b[A\n",
      "Epoch 4:  93%|    | 466/500 [00:01<00:00, 282.04it/s, loss=0.481, v_num=2, val_loss=0.520, val_acc=0.745, train_acc=0.741]\u001b[A\n",
      "Epoch 4:  93%|   | 467/500 [00:01<00:00, 281.55it/s, loss=0.481, v_num=2, val_loss=0.520, val_acc=0.745, train_acc=0.741]\u001b[A\n",
      "Epoch 4:  94%|   | 468/500 [00:01<00:00, 281.44it/s, loss=0.481, v_num=2, val_loss=0.520, val_acc=0.745, train_acc=0.741]\u001b[A\n",
      "Epoch 4:  94%|   | 469/500 [00:01<00:00, 281.28it/s, loss=0.481, v_num=2, val_loss=0.520, val_acc=0.745, train_acc=0.741]\u001b[A\n",
      "Epoch 4:  94%|   | 470/500 [00:01<00:00, 281.29it/s, loss=0.481, v_num=2, val_loss=0.520, val_acc=0.745, train_acc=0.741]\u001b[A\n",
      "Epoch 4:  94%|   | 471/500 [00:01<00:00, 281.42it/s, loss=0.481, v_num=2, val_loss=0.520, val_acc=0.745, train_acc=0.741]\u001b[A\n",
      "Epoch 4:  94%|   | 472/500 [00:01<00:00, 281.47it/s, loss=0.481, v_num=2, val_loss=0.520, val_acc=0.745, train_acc=0.741]\u001b[A\n",
      "Epoch 4:  95%|   | 473/500 [00:01<00:00, 281.57it/s, loss=0.481, v_num=2, val_loss=0.520, val_acc=0.745, train_acc=0.741]\u001b[A\n",
      "Epoch 4:  95%|   | 474/500 [00:01<00:00, 281.69it/s, loss=0.481, v_num=2, val_loss=0.520, val_acc=0.745, train_acc=0.741]\u001b[A\n",
      "Epoch 4:  95%|   | 475/500 [00:01<00:00, 281.82it/s, loss=0.481, v_num=2, val_loss=0.520, val_acc=0.745, train_acc=0.741]\u001b[A\n",
      "Epoch 4:  95%|  | 476/500 [00:01<00:00, 281.94it/s, loss=0.481, v_num=2, val_loss=0.520, val_acc=0.745, train_acc=0.741]\u001b[A\n",
      "Epoch 4:  95%|  | 477/500 [00:01<00:00, 282.07it/s, loss=0.481, v_num=2, val_loss=0.520, val_acc=0.745, train_acc=0.741]\u001b[A\n",
      "Epoch 4:  96%|  | 478/500 [00:01<00:00, 282.21it/s, loss=0.481, v_num=2, val_loss=0.520, val_acc=0.745, train_acc=0.741]\u001b[A\n",
      "Epoch 4:  96%|  | 479/500 [00:01<00:00, 282.35it/s, loss=0.481, v_num=2, val_loss=0.520, val_acc=0.745, train_acc=0.741]\u001b[A\n",
      "Epoch 4:  96%|  | 480/500 [00:01<00:00, 282.42it/s, loss=0.481, v_num=2, val_loss=0.520, val_acc=0.745, train_acc=0.741]\u001b[A\n",
      "Epoch 4:  96%|  | 481/500 [00:01<00:00, 282.61it/s, loss=0.481, v_num=2, val_loss=0.520, val_acc=0.745, train_acc=0.741]\u001b[A\n",
      "Epoch 4:  96%|  | 482/500 [00:01<00:00, 282.78it/s, loss=0.481, v_num=2, val_loss=0.520, val_acc=0.745, train_acc=0.741]\u001b[A\n",
      "Epoch 4:  97%|  | 483/500 [00:01<00:00, 282.91it/s, loss=0.481, v_num=2, val_loss=0.520, val_acc=0.745, train_acc=0.741]\u001b[A\n",
      "Epoch 4:  97%| | 484/500 [00:01<00:00, 283.06it/s, loss=0.481, v_num=2, val_loss=0.520, val_acc=0.745, train_acc=0.741]\u001b[A\n",
      "Epoch 4:  97%| | 485/500 [00:01<00:00, 283.18it/s, loss=0.481, v_num=2, val_loss=0.520, val_acc=0.745, train_acc=0.741]\u001b[A\n",
      "Epoch 4:  97%| | 486/500 [00:01<00:00, 283.34it/s, loss=0.481, v_num=2, val_loss=0.520, val_acc=0.745, train_acc=0.741]\u001b[A\n",
      "Epoch 4:  97%| | 487/500 [00:01<00:00, 283.51it/s, loss=0.481, v_num=2, val_loss=0.520, val_acc=0.745, train_acc=0.741]\u001b[A\n",
      "Epoch 4:  98%| | 488/500 [00:01<00:00, 283.65it/s, loss=0.481, v_num=2, val_loss=0.520, val_acc=0.745, train_acc=0.741]\u001b[A\n",
      "Epoch 4:  98%| | 489/500 [00:01<00:00, 283.67it/s, loss=0.481, v_num=2, val_loss=0.520, val_acc=0.745, train_acc=0.741]\u001b[A\n",
      "Epoch 4:  98%| | 490/500 [00:01<00:00, 283.80it/s, loss=0.481, v_num=2, val_loss=0.520, val_acc=0.745, train_acc=0.741]\u001b[A\n",
      "Epoch 4:  98%| | 491/500 [00:01<00:00, 283.98it/s, loss=0.481, v_num=2, val_loss=0.520, val_acc=0.745, train_acc=0.741]\u001b[A\n",
      "Epoch 4:  98%| | 492/500 [00:01<00:00, 284.05it/s, loss=0.481, v_num=2, val_loss=0.520, val_acc=0.745, train_acc=0.741]\u001b[A\n",
      "Epoch 4:  99%|| 493/500 [00:01<00:00, 284.20it/s, loss=0.481, v_num=2, val_loss=0.520, val_acc=0.745, train_acc=0.741]\u001b[A\n",
      "Epoch 4:  99%|| 494/500 [00:01<00:00, 284.37it/s, loss=0.481, v_num=2, val_loss=0.520, val_acc=0.745, train_acc=0.741]\u001b[A\n",
      "Epoch 4:  99%|| 495/500 [00:01<00:00, 284.46it/s, loss=0.481, v_num=2, val_loss=0.520, val_acc=0.745, train_acc=0.741]\u001b[A\n",
      "Epoch 4:  99%|| 496/500 [00:01<00:00, 284.60it/s, loss=0.481, v_num=2, val_loss=0.520, val_acc=0.745, train_acc=0.741]\u001b[A\n",
      "Epoch 4:  99%|| 497/500 [00:01<00:00, 284.76it/s, loss=0.481, v_num=2, val_loss=0.520, val_acc=0.745, train_acc=0.741]\u001b[A\n",
      "Epoch 4: 100%|| 498/500 [00:01<00:00, 284.84it/s, loss=0.481, v_num=2, val_loss=0.520, val_acc=0.745, train_acc=0.741]\u001b[A\n",
      "Epoch 4: 100%|| 499/500 [00:01<00:00, 284.84it/s, loss=0.481, v_num=2, val_loss=0.520, val_acc=0.745, train_acc=0.741]\u001b[A\n",
      "Epoch 4: 100%|| 500/500 [00:01<00:00, 283.85it/s, loss=0.481, v_num=2, val_loss=0.487, val_acc=0.779, train_acc=0.741]\u001b[A\n",
      "Epoch 5:  90%|     | 450/500 [00:01<00:00, 309.48it/s, loss=0.437, v_num=2, val_loss=0.487, val_acc=0.779, train_acc=0.764]\u001b[A\n",
      "Validation: 0it [00:00, ?it/s]\u001b[A\n",
      "Validation:   0%|                                                                                                                                        | 0/50 [00:00<?, ?it/s]\u001b[A\n",
      "Validation DataLoader 0:   0%|                                                                                                                           | 0/50 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 5:  90%|     | 451/500 [00:01<00:00, 305.64it/s, loss=0.437, v_num=2, val_loss=0.487, val_acc=0.779, train_acc=0.764]\u001b[A\n",
      "Epoch 5:  90%|     | 452/500 [00:01<00:00, 305.63it/s, loss=0.437, v_num=2, val_loss=0.487, val_acc=0.779, train_acc=0.764]\u001b[A\n",
      "Epoch 5:  91%|     | 453/500 [00:01<00:00, 305.59it/s, loss=0.437, v_num=2, val_loss=0.487, val_acc=0.779, train_acc=0.764]\u001b[A\n",
      "Epoch 5:  91%|     | 454/500 [00:01<00:00, 305.67it/s, loss=0.437, v_num=2, val_loss=0.487, val_acc=0.779, train_acc=0.764]\u001b[A\n",
      "Epoch 5:  91%|     | 455/500 [00:01<00:00, 305.69it/s, loss=0.437, v_num=2, val_loss=0.487, val_acc=0.779, train_acc=0.764]\u001b[A\n",
      "Epoch 5:  91%|     | 456/500 [00:01<00:00, 305.71it/s, loss=0.437, v_num=2, val_loss=0.487, val_acc=0.779, train_acc=0.764]\u001b[A\n",
      "Epoch 5:  91%|     | 457/500 [00:01<00:00, 305.75it/s, loss=0.437, v_num=2, val_loss=0.487, val_acc=0.779, train_acc=0.764]\u001b[A\n",
      "Epoch 5:  92%|    | 458/500 [00:01<00:00, 305.82it/s, loss=0.437, v_num=2, val_loss=0.487, val_acc=0.779, train_acc=0.764]\u001b[A\n",
      "Epoch 5:  92%|    | 459/500 [00:01<00:00, 305.90it/s, loss=0.437, v_num=2, val_loss=0.487, val_acc=0.779, train_acc=0.764]\u001b[A\n",
      "Epoch 5:  92%|    | 460/500 [00:01<00:00, 305.94it/s, loss=0.437, v_num=2, val_loss=0.487, val_acc=0.779, train_acc=0.764]\u001b[A\n",
      "Epoch 5:  92%|    | 461/500 [00:01<00:00, 306.01it/s, loss=0.437, v_num=2, val_loss=0.487, val_acc=0.779, train_acc=0.764]\u001b[A\n",
      "Epoch 5:  92%|    | 462/500 [00:01<00:00, 306.14it/s, loss=0.437, v_num=2, val_loss=0.487, val_acc=0.779, train_acc=0.764]\u001b[A\n",
      "Epoch 5:  93%|    | 463/500 [00:01<00:00, 306.24it/s, loss=0.437, v_num=2, val_loss=0.487, val_acc=0.779, train_acc=0.764]\u001b[A\n",
      "Epoch 5:  93%|    | 464/500 [00:01<00:00, 306.30it/s, loss=0.437, v_num=2, val_loss=0.487, val_acc=0.779, train_acc=0.764]\u001b[A\n",
      "Epoch 5:  93%|    | 465/500 [00:01<00:00, 306.34it/s, loss=0.437, v_num=2, val_loss=0.487, val_acc=0.779, train_acc=0.764]\u001b[A\n",
      "Epoch 5:  93%|    | 466/500 [00:01<00:00, 306.53it/s, loss=0.437, v_num=2, val_loss=0.487, val_acc=0.779, train_acc=0.764]\u001b[A\n",
      "Epoch 5:  93%|   | 467/500 [00:01<00:00, 306.62it/s, loss=0.437, v_num=2, val_loss=0.487, val_acc=0.779, train_acc=0.764]\u001b[A\n",
      "Epoch 5:  94%|   | 468/500 [00:01<00:00, 306.74it/s, loss=0.437, v_num=2, val_loss=0.487, val_acc=0.779, train_acc=0.764]\u001b[A\n",
      "Epoch 5:  94%|   | 469/500 [00:01<00:00, 306.87it/s, loss=0.437, v_num=2, val_loss=0.487, val_acc=0.779, train_acc=0.764]\u001b[A\n",
      "Epoch 5:  94%|   | 470/500 [00:01<00:00, 307.04it/s, loss=0.437, v_num=2, val_loss=0.487, val_acc=0.779, train_acc=0.764]\u001b[A\n",
      "Epoch 5:  94%|   | 471/500 [00:01<00:00, 307.21it/s, loss=0.437, v_num=2, val_loss=0.487, val_acc=0.779, train_acc=0.764]\u001b[A\n",
      "Epoch 5:  94%|   | 472/500 [00:01<00:00, 307.40it/s, loss=0.437, v_num=2, val_loss=0.487, val_acc=0.779, train_acc=0.764]\u001b[A\n",
      "Epoch 5:  95%|   | 473/500 [00:01<00:00, 307.51it/s, loss=0.437, v_num=2, val_loss=0.487, val_acc=0.779, train_acc=0.764]\u001b[A\n",
      "Epoch 5:  95%|   | 474/500 [00:01<00:00, 307.59it/s, loss=0.437, v_num=2, val_loss=0.487, val_acc=0.779, train_acc=0.764]\u001b[A\n",
      "Epoch 5:  95%|   | 475/500 [00:01<00:00, 307.63it/s, loss=0.437, v_num=2, val_loss=0.487, val_acc=0.779, train_acc=0.764]\u001b[A\n",
      "Epoch 5:  95%|  | 476/500 [00:01<00:00, 307.76it/s, loss=0.437, v_num=2, val_loss=0.487, val_acc=0.779, train_acc=0.764]\u001b[A\n",
      "Epoch 5:  95%|  | 477/500 [00:01<00:00, 307.86it/s, loss=0.437, v_num=2, val_loss=0.487, val_acc=0.779, train_acc=0.764]\u001b[A\n",
      "Epoch 5:  96%|  | 478/500 [00:01<00:00, 307.98it/s, loss=0.437, v_num=2, val_loss=0.487, val_acc=0.779, train_acc=0.764]\u001b[A\n",
      "Epoch 5:  96%|  | 479/500 [00:01<00:00, 308.08it/s, loss=0.437, v_num=2, val_loss=0.487, val_acc=0.779, train_acc=0.764]\u001b[A\n",
      "Epoch 5:  96%|  | 480/500 [00:01<00:00, 308.16it/s, loss=0.437, v_num=2, val_loss=0.487, val_acc=0.779, train_acc=0.764]\u001b[A\n",
      "Epoch 5:  96%|  | 481/500 [00:01<00:00, 308.23it/s, loss=0.437, v_num=2, val_loss=0.487, val_acc=0.779, train_acc=0.764]\u001b[A\n",
      "Epoch 5:  96%|  | 482/500 [00:01<00:00, 308.26it/s, loss=0.437, v_num=2, val_loss=0.487, val_acc=0.779, train_acc=0.764]\u001b[A\n",
      "Epoch 5:  97%|  | 483/500 [00:01<00:00, 308.34it/s, loss=0.437, v_num=2, val_loss=0.487, val_acc=0.779, train_acc=0.764]\u001b[A\n",
      "Epoch 5:  97%| | 484/500 [00:01<00:00, 308.35it/s, loss=0.437, v_num=2, val_loss=0.487, val_acc=0.779, train_acc=0.764]\u001b[A\n",
      "Epoch 5:  97%| | 485/500 [00:01<00:00, 308.45it/s, loss=0.437, v_num=2, val_loss=0.487, val_acc=0.779, train_acc=0.764]\u001b[A\n",
      "Epoch 5:  97%| | 486/500 [00:01<00:00, 308.65it/s, loss=0.437, v_num=2, val_loss=0.487, val_acc=0.779, train_acc=0.764]\u001b[A\n",
      "Epoch 5:  97%| | 487/500 [00:01<00:00, 308.71it/s, loss=0.437, v_num=2, val_loss=0.487, val_acc=0.779, train_acc=0.764]\u001b[A\n",
      "Epoch 5:  98%| | 488/500 [00:01<00:00, 308.73it/s, loss=0.437, v_num=2, val_loss=0.487, val_acc=0.779, train_acc=0.764]\u001b[A\n",
      "Epoch 5:  98%| | 489/500 [00:01<00:00, 308.75it/s, loss=0.437, v_num=2, val_loss=0.487, val_acc=0.779, train_acc=0.764]\u001b[A\n",
      "Epoch 5:  98%| | 490/500 [00:01<00:00, 308.78it/s, loss=0.437, v_num=2, val_loss=0.487, val_acc=0.779, train_acc=0.764]\u001b[A\n",
      "Epoch 5:  98%| | 491/500 [00:01<00:00, 308.87it/s, loss=0.437, v_num=2, val_loss=0.487, val_acc=0.779, train_acc=0.764]\u001b[A\n",
      "Epoch 5:  98%| | 492/500 [00:01<00:00, 308.95it/s, loss=0.437, v_num=2, val_loss=0.487, val_acc=0.779, train_acc=0.764]\u001b[A\n",
      "Epoch 5:  99%|| 493/500 [00:01<00:00, 309.04it/s, loss=0.437, v_num=2, val_loss=0.487, val_acc=0.779, train_acc=0.764]\u001b[A\n",
      "Epoch 5:  99%|| 494/500 [00:01<00:00, 309.22it/s, loss=0.437, v_num=2, val_loss=0.487, val_acc=0.779, train_acc=0.764]\u001b[A\n",
      "Epoch 5:  99%|| 495/500 [00:01<00:00, 309.33it/s, loss=0.437, v_num=2, val_loss=0.487, val_acc=0.779, train_acc=0.764]\u001b[A\n",
      "Epoch 5:  99%|| 496/500 [00:01<00:00, 309.45it/s, loss=0.437, v_num=2, val_loss=0.487, val_acc=0.779, train_acc=0.764]\u001b[A\n",
      "Epoch 5:  99%|| 497/500 [00:01<00:00, 309.64it/s, loss=0.437, v_num=2, val_loss=0.487, val_acc=0.779, train_acc=0.764]\u001b[A\n",
      "Epoch 5: 100%|| 498/500 [00:01<00:00, 309.75it/s, loss=0.437, v_num=2, val_loss=0.487, val_acc=0.779, train_acc=0.764]\u001b[A\n",
      "Epoch 5: 100%|| 499/500 [00:01<00:00, 309.86it/s, loss=0.437, v_num=2, val_loss=0.487, val_acc=0.779, train_acc=0.764]\u001b[A\n",
      "Epoch 5: 100%|| 500/500 [00:01<00:00, 307.07it/s, loss=0.437, v_num=2, val_loss=0.466, val_acc=0.785, train_acc=0.764]\u001b[A\n",
      "Epoch 6:  90%|     | 450/500 [00:01<00:00, 277.26it/s, loss=0.397, v_num=2, val_loss=0.466, val_acc=0.785, train_acc=0.789]\u001b[A\n",
      "Validation: 0it [00:00, ?it/s]\u001b[A\n",
      "Validation:   0%|                                                                                                                                        | 0/50 [00:00<?, ?it/s]\u001b[A\n",
      "Validation DataLoader 0:   0%|                                                                                                                           | 0/50 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 6:  90%|     | 451/500 [00:01<00:00, 275.69it/s, loss=0.397, v_num=2, val_loss=0.466, val_acc=0.785, train_acc=0.789]\u001b[A\n",
      "Epoch 6:  90%|     | 452/500 [00:01<00:00, 275.73it/s, loss=0.397, v_num=2, val_loss=0.466, val_acc=0.785, train_acc=0.789]\u001b[A\n",
      "Epoch 6:  91%|     | 453/500 [00:01<00:00, 275.74it/s, loss=0.397, v_num=2, val_loss=0.466, val_acc=0.785, train_acc=0.789]\u001b[A\n",
      "Epoch 6:  91%|     | 454/500 [00:01<00:00, 275.72it/s, loss=0.397, v_num=2, val_loss=0.466, val_acc=0.785, train_acc=0.789]\u001b[A\n",
      "Epoch 6:  91%|     | 455/500 [00:01<00:00, 275.76it/s, loss=0.397, v_num=2, val_loss=0.466, val_acc=0.785, train_acc=0.789]\u001b[A\n",
      "Epoch 6:  91%|     | 456/500 [00:01<00:00, 275.80it/s, loss=0.397, v_num=2, val_loss=0.466, val_acc=0.785, train_acc=0.789]\u001b[A\n",
      "Epoch 6:  91%|     | 457/500 [00:01<00:00, 275.75it/s, loss=0.397, v_num=2, val_loss=0.466, val_acc=0.785, train_acc=0.789]\u001b[A\n",
      "Epoch 6:  92%|    | 458/500 [00:01<00:00, 275.85it/s, loss=0.397, v_num=2, val_loss=0.466, val_acc=0.785, train_acc=0.789]\u001b[A\n",
      "Epoch 6:  92%|    | 459/500 [00:01<00:00, 275.93it/s, loss=0.397, v_num=2, val_loss=0.466, val_acc=0.785, train_acc=0.789]\u001b[A\n",
      "Epoch 6:  92%|    | 460/500 [00:01<00:00, 276.03it/s, loss=0.397, v_num=2, val_loss=0.466, val_acc=0.785, train_acc=0.789]\u001b[A\n",
      "Epoch 6:  92%|    | 461/500 [00:01<00:00, 276.14it/s, loss=0.397, v_num=2, val_loss=0.466, val_acc=0.785, train_acc=0.789]\u001b[A\n",
      "Epoch 6:  92%|    | 462/500 [00:01<00:00, 276.17it/s, loss=0.397, v_num=2, val_loss=0.466, val_acc=0.785, train_acc=0.789]\u001b[A\n",
      "Epoch 6:  93%|    | 463/500 [00:01<00:00, 276.28it/s, loss=0.397, v_num=2, val_loss=0.466, val_acc=0.785, train_acc=0.789]\u001b[A\n",
      "Epoch 6:  93%|    | 464/500 [00:01<00:00, 276.37it/s, loss=0.397, v_num=2, val_loss=0.466, val_acc=0.785, train_acc=0.789]\u001b[A\n",
      "Epoch 6:  93%|    | 465/500 [00:01<00:00, 276.41it/s, loss=0.397, v_num=2, val_loss=0.466, val_acc=0.785, train_acc=0.789]\u001b[A\n",
      "Epoch 6:  93%|    | 466/500 [00:01<00:00, 276.44it/s, loss=0.397, v_num=2, val_loss=0.466, val_acc=0.785, train_acc=0.789]\u001b[A\n",
      "Epoch 6:  93%|   | 467/500 [00:01<00:00, 276.58it/s, loss=0.397, v_num=2, val_loss=0.466, val_acc=0.785, train_acc=0.789]\u001b[A\n",
      "Epoch 6:  94%|   | 468/500 [00:01<00:00, 276.58it/s, loss=0.397, v_num=2, val_loss=0.466, val_acc=0.785, train_acc=0.789]\u001b[A\n",
      "Epoch 6:  94%|   | 469/500 [00:01<00:00, 276.62it/s, loss=0.397, v_num=2, val_loss=0.466, val_acc=0.785, train_acc=0.789]\u001b[A\n",
      "Epoch 6:  94%|   | 470/500 [00:01<00:00, 276.60it/s, loss=0.397, v_num=2, val_loss=0.466, val_acc=0.785, train_acc=0.789]\u001b[A\n",
      "Epoch 6:  94%|   | 471/500 [00:01<00:00, 276.60it/s, loss=0.397, v_num=2, val_loss=0.466, val_acc=0.785, train_acc=0.789]\u001b[A\n",
      "Epoch 6:  94%|   | 472/500 [00:01<00:00, 276.63it/s, loss=0.397, v_num=2, val_loss=0.466, val_acc=0.785, train_acc=0.789]\u001b[A\n",
      "Epoch 6:  95%|   | 473/500 [00:01<00:00, 276.70it/s, loss=0.397, v_num=2, val_loss=0.466, val_acc=0.785, train_acc=0.789]\u001b[A\n",
      "Epoch 6:  95%|   | 474/500 [00:01<00:00, 276.70it/s, loss=0.397, v_num=2, val_loss=0.466, val_acc=0.785, train_acc=0.789]\u001b[A\n",
      "Epoch 6:  95%|   | 475/500 [00:01<00:00, 276.75it/s, loss=0.397, v_num=2, val_loss=0.466, val_acc=0.785, train_acc=0.789]\u001b[A\n",
      "Epoch 6:  95%|  | 476/500 [00:01<00:00, 276.72it/s, loss=0.397, v_num=2, val_loss=0.466, val_acc=0.785, train_acc=0.789]\u001b[A\n",
      "Epoch 6:  95%|  | 477/500 [00:01<00:00, 276.72it/s, loss=0.397, v_num=2, val_loss=0.466, val_acc=0.785, train_acc=0.789]\u001b[A\n",
      "Epoch 6:  96%|  | 478/500 [00:01<00:00, 276.73it/s, loss=0.397, v_num=2, val_loss=0.466, val_acc=0.785, train_acc=0.789]\u001b[A\n",
      "Epoch 6:  96%|  | 479/500 [00:01<00:00, 276.75it/s, loss=0.397, v_num=2, val_loss=0.466, val_acc=0.785, train_acc=0.789]\u001b[A\n",
      "Epoch 6:  96%|  | 480/500 [00:01<00:00, 276.83it/s, loss=0.397, v_num=2, val_loss=0.466, val_acc=0.785, train_acc=0.789]\u001b[A\n",
      "Epoch 6:  96%|  | 481/500 [00:01<00:00, 276.89it/s, loss=0.397, v_num=2, val_loss=0.466, val_acc=0.785, train_acc=0.789]\u001b[A\n",
      "Epoch 6:  96%|  | 482/500 [00:01<00:00, 276.85it/s, loss=0.397, v_num=2, val_loss=0.466, val_acc=0.785, train_acc=0.789]\u001b[A\n",
      "Epoch 6:  97%|  | 483/500 [00:01<00:00, 276.91it/s, loss=0.397, v_num=2, val_loss=0.466, val_acc=0.785, train_acc=0.789]\u001b[A\n",
      "Epoch 6:  97%| | 484/500 [00:01<00:00, 276.93it/s, loss=0.397, v_num=2, val_loss=0.466, val_acc=0.785, train_acc=0.789]\u001b[A\n",
      "Epoch 6:  97%| | 485/500 [00:01<00:00, 276.96it/s, loss=0.397, v_num=2, val_loss=0.466, val_acc=0.785, train_acc=0.789]\u001b[A\n",
      "Epoch 6:  97%| | 486/500 [00:01<00:00, 277.01it/s, loss=0.397, v_num=2, val_loss=0.466, val_acc=0.785, train_acc=0.789]\u001b[A\n",
      "Epoch 6:  97%| | 487/500 [00:01<00:00, 277.01it/s, loss=0.397, v_num=2, val_loss=0.466, val_acc=0.785, train_acc=0.789]\u001b[A\n",
      "Epoch 6:  98%| | 488/500 [00:01<00:00, 276.99it/s, loss=0.397, v_num=2, val_loss=0.466, val_acc=0.785, train_acc=0.789]\u001b[A\n",
      "Epoch 6:  98%| | 489/500 [00:01<00:00, 276.97it/s, loss=0.397, v_num=2, val_loss=0.466, val_acc=0.785, train_acc=0.789]\u001b[A\n",
      "Epoch 6:  98%| | 490/500 [00:01<00:00, 276.98it/s, loss=0.397, v_num=2, val_loss=0.466, val_acc=0.785, train_acc=0.789]\u001b[A\n",
      "Epoch 6:  98%| | 491/500 [00:01<00:00, 277.03it/s, loss=0.397, v_num=2, val_loss=0.466, val_acc=0.785, train_acc=0.789]\u001b[A\n",
      "Epoch 6:  98%| | 492/500 [00:01<00:00, 277.03it/s, loss=0.397, v_num=2, val_loss=0.466, val_acc=0.785, train_acc=0.789]\u001b[A\n",
      "Epoch 6:  99%|| 493/500 [00:01<00:00, 277.08it/s, loss=0.397, v_num=2, val_loss=0.466, val_acc=0.785, train_acc=0.789]\u001b[A\n",
      "Epoch 6:  99%|| 494/500 [00:01<00:00, 277.17it/s, loss=0.397, v_num=2, val_loss=0.466, val_acc=0.785, train_acc=0.789]\u001b[A\n",
      "Epoch 6:  99%|| 495/500 [00:01<00:00, 277.25it/s, loss=0.397, v_num=2, val_loss=0.466, val_acc=0.785, train_acc=0.789]\u001b[A\n",
      "Epoch 6:  99%|| 496/500 [00:01<00:00, 277.25it/s, loss=0.397, v_num=2, val_loss=0.466, val_acc=0.785, train_acc=0.789]\u001b[A\n",
      "Epoch 6:  99%|| 497/500 [00:01<00:00, 277.32it/s, loss=0.397, v_num=2, val_loss=0.466, val_acc=0.785, train_acc=0.789]\u001b[A\n",
      "Epoch 6: 100%|| 498/500 [00:01<00:00, 277.26it/s, loss=0.397, v_num=2, val_loss=0.466, val_acc=0.785, train_acc=0.789]\u001b[A\n",
      "Epoch 6: 100%|| 499/500 [00:01<00:00, 277.07it/s, loss=0.397, v_num=2, val_loss=0.466, val_acc=0.785, train_acc=0.789]\u001b[A\n",
      "Epoch 6: 100%|| 500/500 [00:01<00:00, 275.51it/s, loss=0.397, v_num=2, val_loss=0.431, val_acc=0.811, train_acc=0.789]\u001b[A\n",
      "Epoch 7:  90%|      | 450/500 [00:01<00:00, 267.06it/s, loss=0.4, v_num=2, val_loss=0.431, val_acc=0.811, train_acc=0.811]\u001b[A\n",
      "Validation: 0it [00:00, ?it/s]\u001b[A\n",
      "Validation:   0%|                                                                                                                                        | 0/50 [00:00<?, ?it/s]\u001b[A\n",
      "Validation DataLoader 0:   0%|                                                                                                                           | 0/50 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 7:  90%|      | 451/500 [00:01<00:00, 264.22it/s, loss=0.4, v_num=2, val_loss=0.431, val_acc=0.811, train_acc=0.811]\u001b[A\n",
      "Epoch 7:  90%|     | 452/500 [00:01<00:00, 264.34it/s, loss=0.4, v_num=2, val_loss=0.431, val_acc=0.811, train_acc=0.811]\u001b[A\n",
      "Epoch 7:  91%|     | 453/500 [00:01<00:00, 264.46it/s, loss=0.4, v_num=2, val_loss=0.431, val_acc=0.811, train_acc=0.811]\u001b[A\n",
      "Epoch 7:  91%|     | 454/500 [00:01<00:00, 264.57it/s, loss=0.4, v_num=2, val_loss=0.431, val_acc=0.811, train_acc=0.811]\u001b[A\n",
      "Epoch 7:  91%|     | 455/500 [00:01<00:00, 264.65it/s, loss=0.4, v_num=2, val_loss=0.431, val_acc=0.811, train_acc=0.811]\u001b[A\n",
      "Epoch 7:  91%|     | 456/500 [00:01<00:00, 264.69it/s, loss=0.4, v_num=2, val_loss=0.431, val_acc=0.811, train_acc=0.811]\u001b[A\n",
      "Epoch 7:  91%|     | 457/500 [00:01<00:00, 264.69it/s, loss=0.4, v_num=2, val_loss=0.431, val_acc=0.811, train_acc=0.811]\u001b[A\n",
      "Epoch 7:  92%|     | 458/500 [00:01<00:00, 264.64it/s, loss=0.4, v_num=2, val_loss=0.431, val_acc=0.811, train_acc=0.811]\u001b[A\n",
      "Epoch 7:  92%|     | 459/500 [00:01<00:00, 264.69it/s, loss=0.4, v_num=2, val_loss=0.431, val_acc=0.811, train_acc=0.811]\u001b[A\n",
      "Epoch 7:  92%|    | 460/500 [00:01<00:00, 264.73it/s, loss=0.4, v_num=2, val_loss=0.431, val_acc=0.811, train_acc=0.811]\u001b[A\n",
      "Epoch 7:  92%|    | 461/500 [00:01<00:00, 264.79it/s, loss=0.4, v_num=2, val_loss=0.431, val_acc=0.811, train_acc=0.811]\u001b[A\n",
      "Epoch 7:  92%|    | 462/500 [00:01<00:00, 264.89it/s, loss=0.4, v_num=2, val_loss=0.431, val_acc=0.811, train_acc=0.811]\u001b[A\n",
      "Epoch 7:  93%|    | 463/500 [00:01<00:00, 264.98it/s, loss=0.4, v_num=2, val_loss=0.431, val_acc=0.811, train_acc=0.811]\u001b[A\n",
      "Epoch 7:  93%|    | 464/500 [00:01<00:00, 265.02it/s, loss=0.4, v_num=2, val_loss=0.431, val_acc=0.811, train_acc=0.811]\u001b[A\n",
      "Epoch 7:  93%|    | 465/500 [00:01<00:00, 265.15it/s, loss=0.4, v_num=2, val_loss=0.431, val_acc=0.811, train_acc=0.811]\u001b[A\n",
      "Epoch 7:  93%|    | 466/500 [00:01<00:00, 265.28it/s, loss=0.4, v_num=2, val_loss=0.431, val_acc=0.811, train_acc=0.811]\u001b[A\n",
      "Epoch 7:  93%|    | 467/500 [00:01<00:00, 265.47it/s, loss=0.4, v_num=2, val_loss=0.431, val_acc=0.811, train_acc=0.811]\u001b[A\n",
      "Epoch 7:  94%|   | 468/500 [00:01<00:00, 265.59it/s, loss=0.4, v_num=2, val_loss=0.431, val_acc=0.811, train_acc=0.811]\u001b[A\n",
      "Epoch 7:  94%|   | 469/500 [00:01<00:00, 265.63it/s, loss=0.4, v_num=2, val_loss=0.431, val_acc=0.811, train_acc=0.811]\u001b[A\n",
      "Epoch 7:  94%|   | 470/500 [00:01<00:00, 265.69it/s, loss=0.4, v_num=2, val_loss=0.431, val_acc=0.811, train_acc=0.811]\u001b[A\n",
      "Epoch 7:  94%|   | 471/500 [00:01<00:00, 265.74it/s, loss=0.4, v_num=2, val_loss=0.431, val_acc=0.811, train_acc=0.811]\u001b[A\n",
      "Epoch 7:  94%|   | 472/500 [00:01<00:00, 265.80it/s, loss=0.4, v_num=2, val_loss=0.431, val_acc=0.811, train_acc=0.811]\u001b[A\n",
      "Epoch 7:  95%|   | 473/500 [00:01<00:00, 265.86it/s, loss=0.4, v_num=2, val_loss=0.431, val_acc=0.811, train_acc=0.811]\u001b[A\n",
      "Epoch 7:  95%|   | 474/500 [00:01<00:00, 265.94it/s, loss=0.4, v_num=2, val_loss=0.431, val_acc=0.811, train_acc=0.811]\u001b[A\n",
      "Epoch 7:  95%|   | 475/500 [00:01<00:00, 265.98it/s, loss=0.4, v_num=2, val_loss=0.431, val_acc=0.811, train_acc=0.811]\u001b[A\n",
      "Epoch 7:  95%|   | 476/500 [00:01<00:00, 266.06it/s, loss=0.4, v_num=2, val_loss=0.431, val_acc=0.811, train_acc=0.811]\u001b[A\n",
      "Epoch 7:  95%|  | 477/500 [00:01<00:00, 266.14it/s, loss=0.4, v_num=2, val_loss=0.431, val_acc=0.811, train_acc=0.811]\u001b[A\n",
      "Epoch 7:  96%|  | 478/500 [00:01<00:00, 266.20it/s, loss=0.4, v_num=2, val_loss=0.431, val_acc=0.811, train_acc=0.811]\u001b[A\n",
      "Epoch 7:  96%|  | 479/500 [00:01<00:00, 266.30it/s, loss=0.4, v_num=2, val_loss=0.431, val_acc=0.811, train_acc=0.811]\u001b[A\n",
      "Epoch 7:  96%|  | 480/500 [00:01<00:00, 266.39it/s, loss=0.4, v_num=2, val_loss=0.431, val_acc=0.811, train_acc=0.811]\u001b[A\n",
      "Epoch 7:  96%|  | 481/500 [00:01<00:00, 266.48it/s, loss=0.4, v_num=2, val_loss=0.431, val_acc=0.811, train_acc=0.811]\u001b[A\n",
      "Epoch 7:  96%|  | 482/500 [00:01<00:00, 266.57it/s, loss=0.4, v_num=2, val_loss=0.431, val_acc=0.811, train_acc=0.811]\u001b[A\n",
      "Epoch 7:  97%|  | 483/500 [00:01<00:00, 266.67it/s, loss=0.4, v_num=2, val_loss=0.431, val_acc=0.811, train_acc=0.811]\u001b[A\n",
      "Epoch 7:  97%|  | 484/500 [00:01<00:00, 266.73it/s, loss=0.4, v_num=2, val_loss=0.431, val_acc=0.811, train_acc=0.811]\u001b[A\n",
      "Epoch 7:  97%| | 485/500 [00:01<00:00, 266.78it/s, loss=0.4, v_num=2, val_loss=0.431, val_acc=0.811, train_acc=0.811]\u001b[A\n",
      "Epoch 7:  97%| | 486/500 [00:01<00:00, 266.81it/s, loss=0.4, v_num=2, val_loss=0.431, val_acc=0.811, train_acc=0.811]\u001b[A\n",
      "Epoch 7:  97%| | 487/500 [00:01<00:00, 266.86it/s, loss=0.4, v_num=2, val_loss=0.431, val_acc=0.811, train_acc=0.811]\u001b[A\n",
      "Epoch 7:  98%| | 488/500 [00:01<00:00, 266.94it/s, loss=0.4, v_num=2, val_loss=0.431, val_acc=0.811, train_acc=0.811]\u001b[A\n",
      "Epoch 7:  98%| | 489/500 [00:01<00:00, 267.01it/s, loss=0.4, v_num=2, val_loss=0.431, val_acc=0.811, train_acc=0.811]\u001b[A\n",
      "Epoch 7:  98%| | 490/500 [00:01<00:00, 267.10it/s, loss=0.4, v_num=2, val_loss=0.431, val_acc=0.811, train_acc=0.811]\u001b[A\n",
      "Epoch 7:  98%| | 491/500 [00:01<00:00, 267.11it/s, loss=0.4, v_num=2, val_loss=0.431, val_acc=0.811, train_acc=0.811]\u001b[A\n",
      "Epoch 7:  98%| | 492/500 [00:01<00:00, 267.25it/s, loss=0.4, v_num=2, val_loss=0.431, val_acc=0.811, train_acc=0.811]\u001b[A\n",
      "Epoch 7:  99%|| 493/500 [00:01<00:00, 267.36it/s, loss=0.4, v_num=2, val_loss=0.431, val_acc=0.811, train_acc=0.811]\u001b[A\n",
      "Epoch 7:  99%|| 494/500 [00:01<00:00, 267.42it/s, loss=0.4, v_num=2, val_loss=0.431, val_acc=0.811, train_acc=0.811]\u001b[A\n",
      "Epoch 7:  99%|| 495/500 [00:01<00:00, 267.47it/s, loss=0.4, v_num=2, val_loss=0.431, val_acc=0.811, train_acc=0.811]\u001b[A\n",
      "Epoch 7:  99%|| 496/500 [00:01<00:00, 267.61it/s, loss=0.4, v_num=2, val_loss=0.431, val_acc=0.811, train_acc=0.811]\u001b[A\n",
      "Epoch 7:  99%|| 497/500 [00:01<00:00, 267.70it/s, loss=0.4, v_num=2, val_loss=0.431, val_acc=0.811, train_acc=0.811]\u001b[A\n",
      "Epoch 7: 100%|| 498/500 [00:01<00:00, 267.80it/s, loss=0.4, v_num=2, val_loss=0.431, val_acc=0.811, train_acc=0.811]\u001b[A\n",
      "Epoch 7: 100%|| 499/500 [00:01<00:00, 267.88it/s, loss=0.4, v_num=2, val_loss=0.431, val_acc=0.811, train_acc=0.811]\u001b[A\n",
      "Epoch 7: 100%|| 500/500 [00:01<00:00, 266.59it/s, loss=0.4, v_num=2, val_loss=0.413, val_acc=0.826, train_acc=0.811]\u001b[A\n",
      "Epoch 8:  90%|     | 450/500 [00:01<00:00, 293.48it/s, loss=0.396, v_num=2, val_loss=0.413, val_acc=0.826, train_acc=0.824]\u001b[A\n",
      "Validation: 0it [00:00, ?it/s]\u001b[A\n",
      "Validation:   0%|                                                                                                                                        | 0/50 [00:00<?, ?it/s]\u001b[A\n",
      "Validation DataLoader 0:   0%|                                                                                                                           | 0/50 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 8:  90%|     | 451/500 [00:01<00:00, 284.92it/s, loss=0.396, v_num=2, val_loss=0.413, val_acc=0.826, train_acc=0.824]\u001b[A\n",
      "Epoch 8:  90%|     | 452/500 [00:01<00:00, 284.96it/s, loss=0.396, v_num=2, val_loss=0.413, val_acc=0.826, train_acc=0.824]\u001b[A\n",
      "Epoch 8:  91%|     | 453/500 [00:01<00:00, 284.99it/s, loss=0.396, v_num=2, val_loss=0.413, val_acc=0.826, train_acc=0.824]\u001b[A\n",
      "Epoch 8:  91%|     | 454/500 [00:01<00:00, 285.14it/s, loss=0.396, v_num=2, val_loss=0.413, val_acc=0.826, train_acc=0.824]\u001b[A\n",
      "Epoch 8:  91%|     | 455/500 [00:01<00:00, 284.75it/s, loss=0.396, v_num=2, val_loss=0.413, val_acc=0.826, train_acc=0.824]\u001b[A\n",
      "Epoch 8:  91%|     | 456/500 [00:01<00:00, 284.74it/s, loss=0.396, v_num=2, val_loss=0.413, val_acc=0.826, train_acc=0.824]\u001b[A\n",
      "Epoch 8:  91%|     | 457/500 [00:01<00:00, 284.70it/s, loss=0.396, v_num=2, val_loss=0.413, val_acc=0.826, train_acc=0.824]\u001b[A\n",
      "Epoch 8:  92%|    | 458/500 [00:01<00:00, 284.71it/s, loss=0.396, v_num=2, val_loss=0.413, val_acc=0.826, train_acc=0.824]\u001b[A\n",
      "Epoch 8:  92%|    | 459/500 [00:01<00:00, 284.73it/s, loss=0.396, v_num=2, val_loss=0.413, val_acc=0.826, train_acc=0.824]\u001b[A\n",
      "Epoch 8:  92%|    | 460/500 [00:01<00:00, 284.76it/s, loss=0.396, v_num=2, val_loss=0.413, val_acc=0.826, train_acc=0.824]\u001b[A\n",
      "Epoch 8:  92%|    | 461/500 [00:01<00:00, 284.77it/s, loss=0.396, v_num=2, val_loss=0.413, val_acc=0.826, train_acc=0.824]\u001b[A\n",
      "Epoch 8:  92%|    | 462/500 [00:01<00:00, 284.77it/s, loss=0.396, v_num=2, val_loss=0.413, val_acc=0.826, train_acc=0.824]\u001b[A\n",
      "Epoch 8:  93%|    | 463/500 [00:01<00:00, 284.84it/s, loss=0.396, v_num=2, val_loss=0.413, val_acc=0.826, train_acc=0.824]\u001b[A\n",
      "Epoch 8:  93%|    | 464/500 [00:01<00:00, 284.93it/s, loss=0.396, v_num=2, val_loss=0.413, val_acc=0.826, train_acc=0.824]\u001b[A\n",
      "Epoch 8:  93%|    | 465/500 [00:01<00:00, 285.07it/s, loss=0.396, v_num=2, val_loss=0.413, val_acc=0.826, train_acc=0.824]\u001b[A\n",
      "Epoch 8:  93%|    | 466/500 [00:01<00:00, 285.20it/s, loss=0.396, v_num=2, val_loss=0.413, val_acc=0.826, train_acc=0.824]\u001b[A\n",
      "Epoch 8:  93%|   | 467/500 [00:01<00:00, 285.33it/s, loss=0.396, v_num=2, val_loss=0.413, val_acc=0.826, train_acc=0.824]\u001b[A\n",
      "Epoch 8:  94%|   | 468/500 [00:01<00:00, 285.45it/s, loss=0.396, v_num=2, val_loss=0.413, val_acc=0.826, train_acc=0.824]\u001b[A\n",
      "Epoch 8:  94%|   | 469/500 [00:01<00:00, 285.58it/s, loss=0.396, v_num=2, val_loss=0.413, val_acc=0.826, train_acc=0.824]\u001b[A\n",
      "Epoch 8:  94%|   | 470/500 [00:01<00:00, 285.68it/s, loss=0.396, v_num=2, val_loss=0.413, val_acc=0.826, train_acc=0.824]\u001b[A\n",
      "Epoch 8:  94%|   | 471/500 [00:01<00:00, 285.83it/s, loss=0.396, v_num=2, val_loss=0.413, val_acc=0.826, train_acc=0.824]\u001b[A\n",
      "Epoch 8:  94%|   | 472/500 [00:01<00:00, 285.90it/s, loss=0.396, v_num=2, val_loss=0.413, val_acc=0.826, train_acc=0.824]\u001b[A\n",
      "Epoch 8:  95%|   | 473/500 [00:01<00:00, 285.98it/s, loss=0.396, v_num=2, val_loss=0.413, val_acc=0.826, train_acc=0.824]\u001b[A\n",
      "Epoch 8:  95%|   | 474/500 [00:01<00:00, 286.05it/s, loss=0.396, v_num=2, val_loss=0.413, val_acc=0.826, train_acc=0.824]\u001b[A\n",
      "Epoch 8:  95%|   | 475/500 [00:01<00:00, 286.10it/s, loss=0.396, v_num=2, val_loss=0.413, val_acc=0.826, train_acc=0.824]\u001b[A\n",
      "Epoch 8:  95%|  | 476/500 [00:01<00:00, 286.10it/s, loss=0.396, v_num=2, val_loss=0.413, val_acc=0.826, train_acc=0.824]\u001b[A\n",
      "Epoch 8:  95%|  | 477/500 [00:01<00:00, 286.11it/s, loss=0.396, v_num=2, val_loss=0.413, val_acc=0.826, train_acc=0.824]\u001b[A\n",
      "Epoch 8:  96%|  | 478/500 [00:01<00:00, 286.24it/s, loss=0.396, v_num=2, val_loss=0.413, val_acc=0.826, train_acc=0.824]\u001b[A\n",
      "Epoch 8:  96%|  | 479/500 [00:01<00:00, 286.39it/s, loss=0.396, v_num=2, val_loss=0.413, val_acc=0.826, train_acc=0.824]\u001b[A\n",
      "Epoch 8:  96%|  | 480/500 [00:01<00:00, 286.51it/s, loss=0.396, v_num=2, val_loss=0.413, val_acc=0.826, train_acc=0.824]\u001b[A\n",
      "Epoch 8:  96%|  | 481/500 [00:01<00:00, 286.63it/s, loss=0.396, v_num=2, val_loss=0.413, val_acc=0.826, train_acc=0.824]\u001b[A\n",
      "Epoch 8:  96%|  | 482/500 [00:01<00:00, 286.70it/s, loss=0.396, v_num=2, val_loss=0.413, val_acc=0.826, train_acc=0.824]\u001b[A\n",
      "Epoch 8:  97%|  | 483/500 [00:01<00:00, 286.77it/s, loss=0.396, v_num=2, val_loss=0.413, val_acc=0.826, train_acc=0.824]\u001b[A\n",
      "Epoch 8:  97%| | 484/500 [00:01<00:00, 286.87it/s, loss=0.396, v_num=2, val_loss=0.413, val_acc=0.826, train_acc=0.824]\u001b[A\n",
      "Epoch 8:  97%| | 485/500 [00:01<00:00, 286.94it/s, loss=0.396, v_num=2, val_loss=0.413, val_acc=0.826, train_acc=0.824]\u001b[A\n",
      "Epoch 8:  97%| | 486/500 [00:01<00:00, 287.05it/s, loss=0.396, v_num=2, val_loss=0.413, val_acc=0.826, train_acc=0.824]\u001b[A\n",
      "Epoch 8:  97%| | 487/500 [00:01<00:00, 287.17it/s, loss=0.396, v_num=2, val_loss=0.413, val_acc=0.826, train_acc=0.824]\u001b[A\n",
      "Epoch 8:  98%| | 488/500 [00:01<00:00, 287.27it/s, loss=0.396, v_num=2, val_loss=0.413, val_acc=0.826, train_acc=0.824]\u001b[A\n",
      "Epoch 8:  98%| | 489/500 [00:01<00:00, 287.41it/s, loss=0.396, v_num=2, val_loss=0.413, val_acc=0.826, train_acc=0.824]\u001b[A\n",
      "Epoch 8:  98%| | 490/500 [00:01<00:00, 287.57it/s, loss=0.396, v_num=2, val_loss=0.413, val_acc=0.826, train_acc=0.824]\u001b[A\n",
      "Epoch 8:  98%| | 491/500 [00:01<00:00, 287.70it/s, loss=0.396, v_num=2, val_loss=0.413, val_acc=0.826, train_acc=0.824]\u001b[A\n",
      "Epoch 8:  98%| | 492/500 [00:01<00:00, 287.78it/s, loss=0.396, v_num=2, val_loss=0.413, val_acc=0.826, train_acc=0.824]\u001b[A\n",
      "Epoch 8:  99%|| 493/500 [00:01<00:00, 287.84it/s, loss=0.396, v_num=2, val_loss=0.413, val_acc=0.826, train_acc=0.824]\u001b[A\n",
      "Epoch 8:  99%|| 494/500 [00:01<00:00, 287.88it/s, loss=0.396, v_num=2, val_loss=0.413, val_acc=0.826, train_acc=0.824]\u001b[A\n",
      "Epoch 8:  99%|| 495/500 [00:01<00:00, 287.96it/s, loss=0.396, v_num=2, val_loss=0.413, val_acc=0.826, train_acc=0.824]\u001b[A\n",
      "Epoch 8:  99%|| 496/500 [00:01<00:00, 288.03it/s, loss=0.396, v_num=2, val_loss=0.413, val_acc=0.826, train_acc=0.824]\u001b[A\n",
      "Epoch 8:  99%|| 497/500 [00:01<00:00, 288.10it/s, loss=0.396, v_num=2, val_loss=0.413, val_acc=0.826, train_acc=0.824]\u001b[A\n",
      "Epoch 8: 100%|| 498/500 [00:01<00:00, 288.25it/s, loss=0.396, v_num=2, val_loss=0.413, val_acc=0.826, train_acc=0.824]\u001b[A\n",
      "Epoch 8: 100%|| 499/500 [00:01<00:00, 288.38it/s, loss=0.396, v_num=2, val_loss=0.413, val_acc=0.826, train_acc=0.824]\u001b[A\n",
      "Epoch 8: 100%|| 500/500 [00:01<00:00, 287.13it/s, loss=0.396, v_num=2, val_loss=0.384, val_acc=0.837, train_acc=0.824]\u001b[A\n",
      "Epoch 9:  90%|     | 450/500 [00:01<00:00, 302.16it/s, loss=0.357, v_num=2, val_loss=0.384, val_acc=0.837, train_acc=0.835]\u001b[A\n",
      "Validation: 0it [00:00, ?it/s]\u001b[A\n",
      "Validation:   0%|                                                                                                                                        | 0/50 [00:00<?, ?it/s]\u001b[A\n",
      "Validation DataLoader 0:   0%|                                                                                                                           | 0/50 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 9:  90%|     | 451/500 [00:01<00:00, 298.60it/s, loss=0.357, v_num=2, val_loss=0.384, val_acc=0.837, train_acc=0.835]\u001b[A\n",
      "Epoch 9:  90%|     | 452/500 [00:01<00:00, 298.70it/s, loss=0.357, v_num=2, val_loss=0.384, val_acc=0.837, train_acc=0.835]\u001b[A\n",
      "Epoch 9:  91%|     | 453/500 [00:01<00:00, 298.90it/s, loss=0.357, v_num=2, val_loss=0.384, val_acc=0.837, train_acc=0.835]\u001b[A\n",
      "Epoch 9:  91%|     | 454/500 [00:01<00:00, 298.98it/s, loss=0.357, v_num=2, val_loss=0.384, val_acc=0.837, train_acc=0.835]\u001b[A\n",
      "Epoch 9:  91%|     | 455/500 [00:01<00:00, 299.03it/s, loss=0.357, v_num=2, val_loss=0.384, val_acc=0.837, train_acc=0.835]\u001b[A\n",
      "Epoch 9:  91%|     | 456/500 [00:01<00:00, 299.16it/s, loss=0.357, v_num=2, val_loss=0.384, val_acc=0.837, train_acc=0.835]\u001b[A\n",
      "Epoch 9:  91%|     | 457/500 [00:01<00:00, 299.27it/s, loss=0.357, v_num=2, val_loss=0.384, val_acc=0.837, train_acc=0.835]\u001b[A\n",
      "Epoch 9:  92%|    | 458/500 [00:01<00:00, 299.35it/s, loss=0.357, v_num=2, val_loss=0.384, val_acc=0.837, train_acc=0.835]\u001b[A\n",
      "Epoch 9:  92%|    | 459/500 [00:01<00:00, 299.37it/s, loss=0.357, v_num=2, val_loss=0.384, val_acc=0.837, train_acc=0.835]\u001b[A\n",
      "Epoch 9:  92%|    | 460/500 [00:01<00:00, 299.41it/s, loss=0.357, v_num=2, val_loss=0.384, val_acc=0.837, train_acc=0.835]\u001b[A\n",
      "Epoch 9:  92%|    | 461/500 [00:01<00:00, 299.52it/s, loss=0.357, v_num=2, val_loss=0.384, val_acc=0.837, train_acc=0.835]\u001b[A\n",
      "Epoch 9:  92%|    | 462/500 [00:01<00:00, 299.66it/s, loss=0.357, v_num=2, val_loss=0.384, val_acc=0.837, train_acc=0.835]\u001b[A\n",
      "Epoch 9:  93%|    | 463/500 [00:01<00:00, 299.75it/s, loss=0.357, v_num=2, val_loss=0.384, val_acc=0.837, train_acc=0.835]\u001b[A\n",
      "Epoch 9:  93%|    | 464/500 [00:01<00:00, 299.85it/s, loss=0.357, v_num=2, val_loss=0.384, val_acc=0.837, train_acc=0.835]\u001b[A\n",
      "Epoch 9:  93%|    | 465/500 [00:01<00:00, 300.04it/s, loss=0.357, v_num=2, val_loss=0.384, val_acc=0.837, train_acc=0.835]\u001b[A\n",
      "Epoch 9:  93%|    | 466/500 [00:01<00:00, 300.21it/s, loss=0.357, v_num=2, val_loss=0.384, val_acc=0.837, train_acc=0.835]\u001b[A\n",
      "Epoch 9:  93%|   | 467/500 [00:01<00:00, 300.26it/s, loss=0.357, v_num=2, val_loss=0.384, val_acc=0.837, train_acc=0.835]\u001b[A\n",
      "Epoch 9:  94%|   | 468/500 [00:01<00:00, 300.34it/s, loss=0.357, v_num=2, val_loss=0.384, val_acc=0.837, train_acc=0.835]\u001b[A\n",
      "Epoch 9:  94%|   | 469/500 [00:01<00:00, 300.44it/s, loss=0.357, v_num=2, val_loss=0.384, val_acc=0.837, train_acc=0.835]\u001b[A\n",
      "Epoch 9:  94%|   | 470/500 [00:01<00:00, 300.54it/s, loss=0.357, v_num=2, val_loss=0.384, val_acc=0.837, train_acc=0.835]\u001b[A\n",
      "Epoch 9:  94%|   | 471/500 [00:01<00:00, 300.63it/s, loss=0.357, v_num=2, val_loss=0.384, val_acc=0.837, train_acc=0.835]\u001b[A\n",
      "Epoch 9:  94%|   | 472/500 [00:01<00:00, 300.76it/s, loss=0.357, v_num=2, val_loss=0.384, val_acc=0.837, train_acc=0.835]\u001b[A\n",
      "Epoch 9:  95%|   | 473/500 [00:01<00:00, 300.81it/s, loss=0.357, v_num=2, val_loss=0.384, val_acc=0.837, train_acc=0.835]\u001b[A\n",
      "Epoch 9:  95%|   | 474/500 [00:01<00:00, 300.96it/s, loss=0.357, v_num=2, val_loss=0.384, val_acc=0.837, train_acc=0.835]\u001b[A\n",
      "Epoch 9:  95%|   | 475/500 [00:01<00:00, 301.03it/s, loss=0.357, v_num=2, val_loss=0.384, val_acc=0.837, train_acc=0.835]\u001b[A\n",
      "Epoch 9:  95%|  | 476/500 [00:01<00:00, 301.13it/s, loss=0.357, v_num=2, val_loss=0.384, val_acc=0.837, train_acc=0.835]\u001b[A\n",
      "Epoch 9:  95%|  | 477/500 [00:01<00:00, 301.20it/s, loss=0.357, v_num=2, val_loss=0.384, val_acc=0.837, train_acc=0.835]\u001b[A\n",
      "Epoch 9:  96%|  | 478/500 [00:01<00:00, 301.27it/s, loss=0.357, v_num=2, val_loss=0.384, val_acc=0.837, train_acc=0.835]\u001b[A\n",
      "Epoch 9:  96%|  | 479/500 [00:01<00:00, 301.36it/s, loss=0.357, v_num=2, val_loss=0.384, val_acc=0.837, train_acc=0.835]\u001b[A\n",
      "Epoch 9:  96%|  | 480/500 [00:01<00:00, 301.52it/s, loss=0.357, v_num=2, val_loss=0.384, val_acc=0.837, train_acc=0.835]\u001b[A\n",
      "Epoch 9:  96%|  | 481/500 [00:01<00:00, 301.61it/s, loss=0.357, v_num=2, val_loss=0.384, val_acc=0.837, train_acc=0.835]\u001b[A\n",
      "Epoch 9:  96%|  | 482/500 [00:01<00:00, 301.71it/s, loss=0.357, v_num=2, val_loss=0.384, val_acc=0.837, train_acc=0.835]\u001b[A\n",
      "Epoch 9:  97%|  | 483/500 [00:01<00:00, 301.80it/s, loss=0.357, v_num=2, val_loss=0.384, val_acc=0.837, train_acc=0.835]\u001b[A\n",
      "Epoch 9:  97%| | 484/500 [00:01<00:00, 301.95it/s, loss=0.357, v_num=2, val_loss=0.384, val_acc=0.837, train_acc=0.835]\u001b[A\n",
      "Epoch 9:  97%| | 485/500 [00:01<00:00, 302.05it/s, loss=0.357, v_num=2, val_loss=0.384, val_acc=0.837, train_acc=0.835]\u001b[A\n",
      "Epoch 9:  97%| | 486/500 [00:01<00:00, 302.19it/s, loss=0.357, v_num=2, val_loss=0.384, val_acc=0.837, train_acc=0.835]\u001b[A\n",
      "Epoch 9:  97%| | 487/500 [00:01<00:00, 302.24it/s, loss=0.357, v_num=2, val_loss=0.384, val_acc=0.837, train_acc=0.835]\u001b[A\n",
      "Epoch 9:  98%| | 488/500 [00:01<00:00, 302.31it/s, loss=0.357, v_num=2, val_loss=0.384, val_acc=0.837, train_acc=0.835]\u001b[A\n",
      "Epoch 9:  98%| | 489/500 [00:01<00:00, 302.36it/s, loss=0.357, v_num=2, val_loss=0.384, val_acc=0.837, train_acc=0.835]\u001b[A\n",
      "Epoch 9:  98%| | 490/500 [00:01<00:00, 302.47it/s, loss=0.357, v_num=2, val_loss=0.384, val_acc=0.837, train_acc=0.835]\u001b[A\n",
      "Epoch 9:  98%| | 491/500 [00:01<00:00, 302.53it/s, loss=0.357, v_num=2, val_loss=0.384, val_acc=0.837, train_acc=0.835]\u001b[A\n",
      "Epoch 9:  98%| | 492/500 [00:01<00:00, 302.58it/s, loss=0.357, v_num=2, val_loss=0.384, val_acc=0.837, train_acc=0.835]\u001b[A\n",
      "Epoch 9:  99%|| 493/500 [00:01<00:00, 302.59it/s, loss=0.357, v_num=2, val_loss=0.384, val_acc=0.837, train_acc=0.835]\u001b[A\n",
      "Epoch 9:  99%|| 494/500 [00:01<00:00, 302.77it/s, loss=0.357, v_num=2, val_loss=0.384, val_acc=0.837, train_acc=0.835]\u001b[A\n",
      "Epoch 9:  99%|| 495/500 [00:01<00:00, 302.84it/s, loss=0.357, v_num=2, val_loss=0.384, val_acc=0.837, train_acc=0.835]\u001b[A\n",
      "Epoch 9:  99%|| 496/500 [00:01<00:00, 302.91it/s, loss=0.357, v_num=2, val_loss=0.384, val_acc=0.837, train_acc=0.835]\u001b[A\n",
      "Epoch 9:  99%|| 497/500 [00:01<00:00, 303.02it/s, loss=0.357, v_num=2, val_loss=0.384, val_acc=0.837, train_acc=0.835]\u001b[A\n",
      "Epoch 9: 100%|| 498/500 [00:01<00:00, 303.04it/s, loss=0.357, v_num=2, val_loss=0.384, val_acc=0.837, train_acc=0.835]\u001b[A\n",
      "Epoch 9: 100%|| 499/500 [00:01<00:00, 303.16it/s, loss=0.357, v_num=2, val_loss=0.384, val_acc=0.837, train_acc=0.835]\u001b[A\n",
      "Epoch 9: 100%|| 500/500 [00:01<00:00, 300.47it/s, loss=0.357, v_num=2, val_loss=0.415, val_acc=0.813, train_acc=0.835]\u001b[A\n",
      "Epoch 10:  90%|     | 450/500 [00:01<00:00, 295.41it/s, loss=0.343, v_num=2, val_loss=0.415, val_acc=0.813, train_acc=0.842]\u001b[A\n",
      "Validation: 0it [00:00, ?it/s]\u001b[A\n",
      "Validation:   0%|                                                                                                                                        | 0/50 [00:00<?, ?it/s]\u001b[A\n",
      "Validation DataLoader 0:   0%|                                                                                                                           | 0/50 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 10:  90%|     | 451/500 [00:01<00:00, 293.89it/s, loss=0.343, v_num=2, val_loss=0.415, val_acc=0.813, train_acc=0.842]\u001b[A\n",
      "Epoch 10:  90%|     | 452/500 [00:01<00:00, 293.92it/s, loss=0.343, v_num=2, val_loss=0.415, val_acc=0.813, train_acc=0.842]\u001b[A\n",
      "Epoch 10:  91%|     | 453/500 [00:01<00:00, 294.01it/s, loss=0.343, v_num=2, val_loss=0.415, val_acc=0.813, train_acc=0.842]\u001b[A\n",
      "Epoch 10:  91%|     | 454/500 [00:01<00:00, 294.08it/s, loss=0.343, v_num=2, val_loss=0.415, val_acc=0.813, train_acc=0.842]\u001b[A\n",
      "Epoch 10:  91%|     | 455/500 [00:01<00:00, 294.20it/s, loss=0.343, v_num=2, val_loss=0.415, val_acc=0.813, train_acc=0.842]\u001b[A\n",
      "Epoch 10:  91%|     | 456/500 [00:01<00:00, 294.34it/s, loss=0.343, v_num=2, val_loss=0.415, val_acc=0.813, train_acc=0.842]\u001b[A\n",
      "Epoch 10:  91%|     | 457/500 [00:01<00:00, 294.48it/s, loss=0.343, v_num=2, val_loss=0.415, val_acc=0.813, train_acc=0.842]\u001b[A\n",
      "Epoch 10:  92%|    | 458/500 [00:01<00:00, 294.69it/s, loss=0.343, v_num=2, val_loss=0.415, val_acc=0.813, train_acc=0.842]\u001b[A\n",
      "Epoch 10:  92%|    | 459/500 [00:01<00:00, 294.83it/s, loss=0.343, v_num=2, val_loss=0.415, val_acc=0.813, train_acc=0.842]\u001b[A\n",
      "Epoch 10:  92%|    | 460/500 [00:01<00:00, 294.91it/s, loss=0.343, v_num=2, val_loss=0.415, val_acc=0.813, train_acc=0.842]\u001b[A\n",
      "Epoch 10:  92%|    | 461/500 [00:01<00:00, 295.00it/s, loss=0.343, v_num=2, val_loss=0.415, val_acc=0.813, train_acc=0.842]\u001b[A\n",
      "Epoch 10:  92%|    | 462/500 [00:01<00:00, 295.07it/s, loss=0.343, v_num=2, val_loss=0.415, val_acc=0.813, train_acc=0.842]\u001b[A\n",
      "Epoch 10:  93%|    | 463/500 [00:01<00:00, 295.19it/s, loss=0.343, v_num=2, val_loss=0.415, val_acc=0.813, train_acc=0.842]\u001b[A\n",
      "Epoch 10:  93%|    | 464/500 [00:01<00:00, 295.34it/s, loss=0.343, v_num=2, val_loss=0.415, val_acc=0.813, train_acc=0.842]\u001b[A\n",
      "Epoch 10:  93%|    | 465/500 [00:01<00:00, 295.45it/s, loss=0.343, v_num=2, val_loss=0.415, val_acc=0.813, train_acc=0.842]\u001b[A\n",
      "Epoch 10:  93%|    | 466/500 [00:01<00:00, 295.56it/s, loss=0.343, v_num=2, val_loss=0.415, val_acc=0.813, train_acc=0.842]\u001b[A\n",
      "Epoch 10:  93%|   | 467/500 [00:01<00:00, 295.61it/s, loss=0.343, v_num=2, val_loss=0.415, val_acc=0.813, train_acc=0.842]\u001b[A\n",
      "Epoch 10:  94%|   | 468/500 [00:01<00:00, 295.66it/s, loss=0.343, v_num=2, val_loss=0.415, val_acc=0.813, train_acc=0.842]\u001b[A\n",
      "Epoch 10:  94%|   | 469/500 [00:01<00:00, 295.67it/s, loss=0.343, v_num=2, val_loss=0.415, val_acc=0.813, train_acc=0.842]\u001b[A\n",
      "Epoch 10:  94%|   | 470/500 [00:01<00:00, 295.71it/s, loss=0.343, v_num=2, val_loss=0.415, val_acc=0.813, train_acc=0.842]\u001b[A\n",
      "Epoch 10:  94%|   | 471/500 [00:01<00:00, 295.67it/s, loss=0.343, v_num=2, val_loss=0.415, val_acc=0.813, train_acc=0.842]\u001b[A\n",
      "Epoch 10:  94%|   | 472/500 [00:01<00:00, 295.72it/s, loss=0.343, v_num=2, val_loss=0.415, val_acc=0.813, train_acc=0.842]\u001b[A\n",
      "Epoch 10:  95%|   | 473/500 [00:01<00:00, 295.82it/s, loss=0.343, v_num=2, val_loss=0.415, val_acc=0.813, train_acc=0.842]\u001b[A\n",
      "Epoch 10:  95%|   | 474/500 [00:01<00:00, 295.96it/s, loss=0.343, v_num=2, val_loss=0.415, val_acc=0.813, train_acc=0.842]\u001b[A\n",
      "Epoch 10:  95%|  | 475/500 [00:01<00:00, 296.05it/s, loss=0.343, v_num=2, val_loss=0.415, val_acc=0.813, train_acc=0.842]\u001b[A\n",
      "Epoch 10:  95%|  | 476/500 [00:01<00:00, 296.13it/s, loss=0.343, v_num=2, val_loss=0.415, val_acc=0.813, train_acc=0.842]\u001b[A\n",
      "Epoch 10:  95%|  | 477/500 [00:01<00:00, 296.19it/s, loss=0.343, v_num=2, val_loss=0.415, val_acc=0.813, train_acc=0.842]\u001b[A\n",
      "Epoch 10:  96%|  | 478/500 [00:01<00:00, 296.26it/s, loss=0.343, v_num=2, val_loss=0.415, val_acc=0.813, train_acc=0.842]\u001b[A\n",
      "Epoch 10:  96%|  | 479/500 [00:01<00:00, 296.33it/s, loss=0.343, v_num=2, val_loss=0.415, val_acc=0.813, train_acc=0.842]\u001b[A\n",
      "Epoch 10:  96%|  | 480/500 [00:01<00:00, 296.40it/s, loss=0.343, v_num=2, val_loss=0.415, val_acc=0.813, train_acc=0.842]\u001b[A\n",
      "Epoch 10:  96%|  | 481/500 [00:01<00:00, 296.50it/s, loss=0.343, v_num=2, val_loss=0.415, val_acc=0.813, train_acc=0.842]\u001b[A\n",
      "Epoch 10:  96%|  | 482/500 [00:01<00:00, 296.59it/s, loss=0.343, v_num=2, val_loss=0.415, val_acc=0.813, train_acc=0.842]\u001b[A\n",
      "Epoch 10:  97%|  | 483/500 [00:01<00:00, 296.64it/s, loss=0.343, v_num=2, val_loss=0.415, val_acc=0.813, train_acc=0.842]\u001b[A\n",
      "Epoch 10:  97%| | 484/500 [00:01<00:00, 296.77it/s, loss=0.343, v_num=2, val_loss=0.415, val_acc=0.813, train_acc=0.842]\u001b[A\n",
      "Epoch 10:  97%| | 485/500 [00:01<00:00, 296.93it/s, loss=0.343, v_num=2, val_loss=0.415, val_acc=0.813, train_acc=0.842]\u001b[A\n",
      "Epoch 10:  97%| | 486/500 [00:01<00:00, 297.12it/s, loss=0.343, v_num=2, val_loss=0.415, val_acc=0.813, train_acc=0.842]\u001b[A\n",
      "Epoch 10:  97%| | 487/500 [00:01<00:00, 297.27it/s, loss=0.343, v_num=2, val_loss=0.415, val_acc=0.813, train_acc=0.842]\u001b[A\n",
      "Epoch 10:  98%| | 488/500 [00:01<00:00, 297.35it/s, loss=0.343, v_num=2, val_loss=0.415, val_acc=0.813, train_acc=0.842]\u001b[A\n",
      "Epoch 10:  98%| | 489/500 [00:01<00:00, 297.49it/s, loss=0.343, v_num=2, val_loss=0.415, val_acc=0.813, train_acc=0.842]\u001b[A\n",
      "Epoch 10:  98%| | 490/500 [00:01<00:00, 297.57it/s, loss=0.343, v_num=2, val_loss=0.415, val_acc=0.813, train_acc=0.842]\u001b[A\n",
      "Epoch 10:  98%| | 491/500 [00:01<00:00, 297.72it/s, loss=0.343, v_num=2, val_loss=0.415, val_acc=0.813, train_acc=0.842]\u001b[A\n",
      "Epoch 10:  98%| | 492/500 [00:01<00:00, 297.90it/s, loss=0.343, v_num=2, val_loss=0.415, val_acc=0.813, train_acc=0.842]\u001b[A\n",
      "Epoch 10:  99%|| 493/500 [00:01<00:00, 297.96it/s, loss=0.343, v_num=2, val_loss=0.415, val_acc=0.813, train_acc=0.842]\u001b[A\n",
      "Epoch 10:  99%|| 494/500 [00:01<00:00, 298.00it/s, loss=0.343, v_num=2, val_loss=0.415, val_acc=0.813, train_acc=0.842]\u001b[A\n",
      "Epoch 10:  99%|| 495/500 [00:01<00:00, 298.06it/s, loss=0.343, v_num=2, val_loss=0.415, val_acc=0.813, train_acc=0.842]\u001b[A\n",
      "Epoch 10:  99%|| 496/500 [00:01<00:00, 298.14it/s, loss=0.343, v_num=2, val_loss=0.415, val_acc=0.813, train_acc=0.842]\u001b[A\n",
      "Epoch 10:  99%|| 497/500 [00:01<00:00, 298.25it/s, loss=0.343, v_num=2, val_loss=0.415, val_acc=0.813, train_acc=0.842]\u001b[A\n",
      "Epoch 10: 100%|| 498/500 [00:01<00:00, 298.28it/s, loss=0.343, v_num=2, val_loss=0.415, val_acc=0.813, train_acc=0.842]\u001b[A\n",
      "Epoch 10: 100%|| 499/500 [00:01<00:00, 298.33it/s, loss=0.343, v_num=2, val_loss=0.415, val_acc=0.813, train_acc=0.842]\u001b[A\n",
      "Epoch 10: 100%|| 500/500 [00:01<00:00, 297.04it/s, loss=0.343, v_num=2, val_loss=0.377, val_acc=0.851, train_acc=0.842]\u001b[A\n",
      "Epoch 11:  90%|     | 450/500 [00:01<00:00, 297.29it/s, loss=0.329, v_num=2, val_loss=0.377, val_acc=0.851, train_acc=0.846]\u001b[A\n",
      "Validation: 0it [00:00, ?it/s]\u001b[A\n",
      "Validation:   0%|                                                                                                                                        | 0/50 [00:00<?, ?it/s]\u001b[A\n",
      "Validation DataLoader 0:   0%|                                                                                                                           | 0/50 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 11:  90%|     | 451/500 [00:01<00:00, 294.40it/s, loss=0.329, v_num=2, val_loss=0.377, val_acc=0.851, train_acc=0.846]\u001b[A\n",
      "Epoch 11:  90%|     | 452/500 [00:01<00:00, 294.46it/s, loss=0.329, v_num=2, val_loss=0.377, val_acc=0.851, train_acc=0.846]\u001b[A\n",
      "Epoch 11:  91%|     | 453/500 [00:01<00:00, 294.49it/s, loss=0.329, v_num=2, val_loss=0.377, val_acc=0.851, train_acc=0.846]\u001b[A\n",
      "Epoch 11:  91%|     | 454/500 [00:01<00:00, 294.52it/s, loss=0.329, v_num=2, val_loss=0.377, val_acc=0.851, train_acc=0.846]\u001b[A\n",
      "Epoch 11:  91%|     | 455/500 [00:01<00:00, 294.55it/s, loss=0.329, v_num=2, val_loss=0.377, val_acc=0.851, train_acc=0.846]\u001b[A\n",
      "Epoch 11:  91%|     | 456/500 [00:01<00:00, 294.58it/s, loss=0.329, v_num=2, val_loss=0.377, val_acc=0.851, train_acc=0.846]\u001b[A\n",
      "Epoch 11:  91%|     | 457/500 [00:01<00:00, 294.59it/s, loss=0.329, v_num=2, val_loss=0.377, val_acc=0.851, train_acc=0.846]\u001b[A\n",
      "Epoch 11:  92%|    | 458/500 [00:01<00:00, 294.55it/s, loss=0.329, v_num=2, val_loss=0.377, val_acc=0.851, train_acc=0.846]\u001b[A\n",
      "Epoch 11:  92%|    | 459/500 [00:01<00:00, 294.50it/s, loss=0.329, v_num=2, val_loss=0.377, val_acc=0.851, train_acc=0.846]\u001b[A\n",
      "Epoch 11:  92%|    | 460/500 [00:01<00:00, 294.59it/s, loss=0.329, v_num=2, val_loss=0.377, val_acc=0.851, train_acc=0.846]\u001b[A\n",
      "Epoch 11:  92%|    | 461/500 [00:01<00:00, 294.67it/s, loss=0.329, v_num=2, val_loss=0.377, val_acc=0.851, train_acc=0.846]\u001b[A\n",
      "Epoch 11:  92%|    | 462/500 [00:01<00:00, 294.78it/s, loss=0.329, v_num=2, val_loss=0.377, val_acc=0.851, train_acc=0.846]\u001b[A\n",
      "Epoch 11:  93%|    | 463/500 [00:01<00:00, 294.81it/s, loss=0.329, v_num=2, val_loss=0.377, val_acc=0.851, train_acc=0.846]\u001b[A\n",
      "Epoch 11:  93%|    | 464/500 [00:01<00:00, 294.72it/s, loss=0.329, v_num=2, val_loss=0.377, val_acc=0.851, train_acc=0.846]\u001b[A\n",
      "Epoch 11:  93%|    | 465/500 [00:01<00:00, 287.74it/s, loss=0.329, v_num=2, val_loss=0.377, val_acc=0.851, train_acc=0.846]\u001b[A\n",
      "Epoch 11:  93%|    | 466/500 [00:01<00:00, 287.56it/s, loss=0.329, v_num=2, val_loss=0.377, val_acc=0.851, train_acc=0.846]\u001b[A\n",
      "Epoch 11:  93%|   | 467/500 [00:01<00:00, 287.61it/s, loss=0.329, v_num=2, val_loss=0.377, val_acc=0.851, train_acc=0.846]\u001b[A\n",
      "Epoch 11:  94%|   | 468/500 [00:01<00:00, 287.63it/s, loss=0.329, v_num=2, val_loss=0.377, val_acc=0.851, train_acc=0.846]\u001b[A\n",
      "Epoch 11:  94%|   | 469/500 [00:01<00:00, 287.42it/s, loss=0.329, v_num=2, val_loss=0.377, val_acc=0.851, train_acc=0.846]\u001b[A\n",
      "Epoch 11:  94%|   | 470/500 [00:01<00:00, 287.31it/s, loss=0.329, v_num=2, val_loss=0.377, val_acc=0.851, train_acc=0.846]\u001b[A\n",
      "Epoch 11:  94%|   | 471/500 [00:01<00:00, 287.22it/s, loss=0.329, v_num=2, val_loss=0.377, val_acc=0.851, train_acc=0.846]\u001b[A\n",
      "Epoch 11:  94%|   | 472/500 [00:01<00:00, 287.22it/s, loss=0.329, v_num=2, val_loss=0.377, val_acc=0.851, train_acc=0.846]\u001b[A\n",
      "Epoch 11:  95%|   | 473/500 [00:01<00:00, 287.19it/s, loss=0.329, v_num=2, val_loss=0.377, val_acc=0.851, train_acc=0.846]\u001b[A\n",
      "Epoch 11:  95%|   | 474/500 [00:01<00:00, 287.17it/s, loss=0.329, v_num=2, val_loss=0.377, val_acc=0.851, train_acc=0.846]\u001b[A\n",
      "Epoch 11:  95%|  | 475/500 [00:01<00:00, 287.23it/s, loss=0.329, v_num=2, val_loss=0.377, val_acc=0.851, train_acc=0.846]\u001b[A\n",
      "Epoch 11:  95%|  | 476/500 [00:01<00:00, 287.25it/s, loss=0.329, v_num=2, val_loss=0.377, val_acc=0.851, train_acc=0.846]\u001b[A\n",
      "Epoch 11:  95%|  | 477/500 [00:01<00:00, 287.28it/s, loss=0.329, v_num=2, val_loss=0.377, val_acc=0.851, train_acc=0.846]\u001b[A\n",
      "Epoch 11:  96%|  | 478/500 [00:01<00:00, 287.35it/s, loss=0.329, v_num=2, val_loss=0.377, val_acc=0.851, train_acc=0.846]\u001b[A\n",
      "Epoch 11:  96%|  | 479/500 [00:01<00:00, 287.41it/s, loss=0.329, v_num=2, val_loss=0.377, val_acc=0.851, train_acc=0.846]\u001b[A\n",
      "Epoch 11:  96%|  | 480/500 [00:01<00:00, 287.49it/s, loss=0.329, v_num=2, val_loss=0.377, val_acc=0.851, train_acc=0.846]\u001b[A\n",
      "Epoch 11:  96%|  | 481/500 [00:01<00:00, 287.56it/s, loss=0.329, v_num=2, val_loss=0.377, val_acc=0.851, train_acc=0.846]\u001b[A\n",
      "Epoch 11:  96%|  | 482/500 [00:01<00:00, 287.62it/s, loss=0.329, v_num=2, val_loss=0.377, val_acc=0.851, train_acc=0.846]\u001b[A\n",
      "Epoch 11:  97%|  | 483/500 [00:01<00:00, 287.64it/s, loss=0.329, v_num=2, val_loss=0.377, val_acc=0.851, train_acc=0.846]\u001b[A\n",
      "Epoch 11:  97%| | 484/500 [00:01<00:00, 287.78it/s, loss=0.329, v_num=2, val_loss=0.377, val_acc=0.851, train_acc=0.846]\u001b[A\n",
      "Epoch 11:  97%| | 485/500 [00:01<00:00, 287.82it/s, loss=0.329, v_num=2, val_loss=0.377, val_acc=0.851, train_acc=0.846]\u001b[A\n",
      "Epoch 11:  97%| | 486/500 [00:01<00:00, 287.90it/s, loss=0.329, v_num=2, val_loss=0.377, val_acc=0.851, train_acc=0.846]\u001b[A\n",
      "Epoch 11:  97%| | 487/500 [00:01<00:00, 287.90it/s, loss=0.329, v_num=2, val_loss=0.377, val_acc=0.851, train_acc=0.846]\u001b[A\n",
      "Epoch 11:  98%| | 488/500 [00:01<00:00, 287.95it/s, loss=0.329, v_num=2, val_loss=0.377, val_acc=0.851, train_acc=0.846]\u001b[A\n",
      "Epoch 11:  98%| | 489/500 [00:01<00:00, 287.90it/s, loss=0.329, v_num=2, val_loss=0.377, val_acc=0.851, train_acc=0.846]\u001b[A\n",
      "Epoch 11:  98%| | 490/500 [00:01<00:00, 287.89it/s, loss=0.329, v_num=2, val_loss=0.377, val_acc=0.851, train_acc=0.846]\u001b[A\n",
      "Epoch 11:  98%| | 491/500 [00:01<00:00, 287.93it/s, loss=0.329, v_num=2, val_loss=0.377, val_acc=0.851, train_acc=0.846]\u001b[A\n",
      "Epoch 11:  98%| | 492/500 [00:01<00:00, 287.94it/s, loss=0.329, v_num=2, val_loss=0.377, val_acc=0.851, train_acc=0.846]\u001b[A\n",
      "Epoch 11:  99%|| 493/500 [00:01<00:00, 287.94it/s, loss=0.329, v_num=2, val_loss=0.377, val_acc=0.851, train_acc=0.846]\u001b[A\n",
      "Epoch 11:  99%|| 494/500 [00:01<00:00, 288.04it/s, loss=0.329, v_num=2, val_loss=0.377, val_acc=0.851, train_acc=0.846]\u001b[A\n",
      "Epoch 11:  99%|| 495/500 [00:01<00:00, 288.11it/s, loss=0.329, v_num=2, val_loss=0.377, val_acc=0.851, train_acc=0.846]\u001b[A\n",
      "Epoch 11:  99%|| 496/500 [00:01<00:00, 288.17it/s, loss=0.329, v_num=2, val_loss=0.377, val_acc=0.851, train_acc=0.846]\u001b[A\n",
      "Epoch 11:  99%|| 497/500 [00:01<00:00, 288.21it/s, loss=0.329, v_num=2, val_loss=0.377, val_acc=0.851, train_acc=0.846]\u001b[A\n",
      "Epoch 11: 100%|| 498/500 [00:01<00:00, 288.29it/s, loss=0.329, v_num=2, val_loss=0.377, val_acc=0.851, train_acc=0.846]\u001b[A\n",
      "Epoch 11: 100%|| 499/500 [00:01<00:00, 288.33it/s, loss=0.329, v_num=2, val_loss=0.377, val_acc=0.851, train_acc=0.846]\u001b[A\n",
      "Epoch 11: 100%|| 500/500 [00:01<00:00, 286.24it/s, loss=0.329, v_num=2, val_loss=0.368, val_acc=0.848, train_acc=0.846]\u001b[A\n",
      "Epoch 12:  90%|     | 450/500 [00:01<00:00, 293.21it/s, loss=0.338, v_num=2, val_loss=0.368, val_acc=0.848, train_acc=0.856]\u001b[A\n",
      "Validation: 0it [00:00, ?it/s]\u001b[A\n",
      "Validation:   0%|                                                                                                                                        | 0/50 [00:00<?, ?it/s]\u001b[A\n",
      "Validation DataLoader 0:   0%|                                                                                                                           | 0/50 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 12:  90%|     | 451/500 [00:01<00:00, 291.26it/s, loss=0.338, v_num=2, val_loss=0.368, val_acc=0.848, train_acc=0.856]\u001b[A\n",
      "Epoch 12:  90%|     | 452/500 [00:01<00:00, 291.24it/s, loss=0.338, v_num=2, val_loss=0.368, val_acc=0.848, train_acc=0.856]\u001b[A\n",
      "Epoch 12:  91%|     | 453/500 [00:01<00:00, 291.32it/s, loss=0.338, v_num=2, val_loss=0.368, val_acc=0.848, train_acc=0.856]\u001b[A\n",
      "Epoch 12:  91%|     | 454/500 [00:01<00:00, 291.44it/s, loss=0.338, v_num=2, val_loss=0.368, val_acc=0.848, train_acc=0.856]\u001b[A\n",
      "Epoch 12:  91%|     | 455/500 [00:01<00:00, 291.51it/s, loss=0.338, v_num=2, val_loss=0.368, val_acc=0.848, train_acc=0.856]\u001b[A\n",
      "Epoch 12:  91%|     | 456/500 [00:01<00:00, 291.51it/s, loss=0.338, v_num=2, val_loss=0.368, val_acc=0.848, train_acc=0.856]\u001b[A\n",
      "Epoch 12:  91%|     | 457/500 [00:01<00:00, 291.56it/s, loss=0.338, v_num=2, val_loss=0.368, val_acc=0.848, train_acc=0.856]\u001b[A\n",
      "Epoch 12:  92%|    | 458/500 [00:01<00:00, 291.66it/s, loss=0.338, v_num=2, val_loss=0.368, val_acc=0.848, train_acc=0.856]\u001b[A\n",
      "Epoch 12:  92%|    | 459/500 [00:01<00:00, 291.69it/s, loss=0.338, v_num=2, val_loss=0.368, val_acc=0.848, train_acc=0.856]\u001b[A\n",
      "Epoch 12:  92%|    | 460/500 [00:01<00:00, 291.75it/s, loss=0.338, v_num=2, val_loss=0.368, val_acc=0.848, train_acc=0.856]\u001b[A\n",
      "Epoch 12:  92%|    | 461/500 [00:01<00:00, 291.74it/s, loss=0.338, v_num=2, val_loss=0.368, val_acc=0.848, train_acc=0.856]\u001b[A\n",
      "Epoch 12:  92%|    | 462/500 [00:01<00:00, 291.83it/s, loss=0.338, v_num=2, val_loss=0.368, val_acc=0.848, train_acc=0.856]\u001b[A\n",
      "Epoch 12:  93%|    | 463/500 [00:01<00:00, 291.91it/s, loss=0.338, v_num=2, val_loss=0.368, val_acc=0.848, train_acc=0.856]\u001b[A\n",
      "Epoch 12:  93%|    | 464/500 [00:01<00:00, 292.03it/s, loss=0.338, v_num=2, val_loss=0.368, val_acc=0.848, train_acc=0.856]\u001b[A\n",
      "Epoch 12:  93%|    | 465/500 [00:01<00:00, 292.10it/s, loss=0.338, v_num=2, val_loss=0.368, val_acc=0.848, train_acc=0.856]\u001b[A\n",
      "Epoch 12:  93%|    | 466/500 [00:01<00:00, 292.09it/s, loss=0.338, v_num=2, val_loss=0.368, val_acc=0.848, train_acc=0.856]\u001b[A\n",
      "Epoch 12:  93%|   | 467/500 [00:01<00:00, 292.13it/s, loss=0.338, v_num=2, val_loss=0.368, val_acc=0.848, train_acc=0.856]\u001b[A\n",
      "Epoch 12:  94%|   | 468/500 [00:01<00:00, 292.22it/s, loss=0.338, v_num=2, val_loss=0.368, val_acc=0.848, train_acc=0.856]\u001b[A\n",
      "Epoch 12:  94%|   | 469/500 [00:01<00:00, 292.13it/s, loss=0.338, v_num=2, val_loss=0.368, val_acc=0.848, train_acc=0.856]\u001b[A\n",
      "Epoch 12:  94%|   | 470/500 [00:01<00:00, 292.07it/s, loss=0.338, v_num=2, val_loss=0.368, val_acc=0.848, train_acc=0.856]\u001b[A\n",
      "Epoch 12:  94%|   | 471/500 [00:01<00:00, 292.08it/s, loss=0.338, v_num=2, val_loss=0.368, val_acc=0.848, train_acc=0.856]\u001b[A\n",
      "Epoch 12:  94%|   | 472/500 [00:01<00:00, 292.18it/s, loss=0.338, v_num=2, val_loss=0.368, val_acc=0.848, train_acc=0.856]\u001b[A\n",
      "Epoch 12:  95%|   | 473/500 [00:01<00:00, 292.23it/s, loss=0.338, v_num=2, val_loss=0.368, val_acc=0.848, train_acc=0.856]\u001b[A\n",
      "Epoch 12:  95%|   | 474/500 [00:01<00:00, 292.34it/s, loss=0.338, v_num=2, val_loss=0.368, val_acc=0.848, train_acc=0.856]\u001b[A\n",
      "Epoch 12:  95%|  | 475/500 [00:01<00:00, 292.40it/s, loss=0.338, v_num=2, val_loss=0.368, val_acc=0.848, train_acc=0.856]\u001b[A\n",
      "Epoch 12:  95%|  | 476/500 [00:01<00:00, 292.54it/s, loss=0.338, v_num=2, val_loss=0.368, val_acc=0.848, train_acc=0.856]\u001b[A\n",
      "Epoch 12:  95%|  | 477/500 [00:01<00:00, 292.53it/s, loss=0.338, v_num=2, val_loss=0.368, val_acc=0.848, train_acc=0.856]\u001b[A\n",
      "Epoch 12:  96%|  | 478/500 [00:01<00:00, 292.60it/s, loss=0.338, v_num=2, val_loss=0.368, val_acc=0.848, train_acc=0.856]\u001b[A\n",
      "Epoch 12:  96%|  | 479/500 [00:01<00:00, 292.56it/s, loss=0.338, v_num=2, val_loss=0.368, val_acc=0.848, train_acc=0.856]\u001b[A\n",
      "Epoch 12:  96%|  | 480/500 [00:01<00:00, 292.57it/s, loss=0.338, v_num=2, val_loss=0.368, val_acc=0.848, train_acc=0.856]\u001b[A\n",
      "Epoch 12:  96%|  | 481/500 [00:01<00:00, 292.57it/s, loss=0.338, v_num=2, val_loss=0.368, val_acc=0.848, train_acc=0.856]\u001b[A\n",
      "Epoch 12:  96%|  | 482/500 [00:01<00:00, 292.49it/s, loss=0.338, v_num=2, val_loss=0.368, val_acc=0.848, train_acc=0.856]\u001b[A\n",
      "Epoch 12:  97%|  | 483/500 [00:01<00:00, 292.56it/s, loss=0.338, v_num=2, val_loss=0.368, val_acc=0.848, train_acc=0.856]\u001b[A\n",
      "Epoch 12:  97%| | 484/500 [00:01<00:00, 292.56it/s, loss=0.338, v_num=2, val_loss=0.368, val_acc=0.848, train_acc=0.856]\u001b[A\n",
      "Epoch 12:  97%| | 485/500 [00:01<00:00, 292.62it/s, loss=0.338, v_num=2, val_loss=0.368, val_acc=0.848, train_acc=0.856]\u001b[A\n",
      "Epoch 12:  97%| | 486/500 [00:01<00:00, 292.59it/s, loss=0.338, v_num=2, val_loss=0.368, val_acc=0.848, train_acc=0.856]\u001b[A\n",
      "Epoch 12:  97%| | 487/500 [00:01<00:00, 292.61it/s, loss=0.338, v_num=2, val_loss=0.368, val_acc=0.848, train_acc=0.856]\u001b[A\n",
      "Epoch 12:  98%| | 488/500 [00:01<00:00, 292.73it/s, loss=0.338, v_num=2, val_loss=0.368, val_acc=0.848, train_acc=0.856]\u001b[A\n",
      "Epoch 12:  98%| | 489/500 [00:01<00:00, 292.86it/s, loss=0.338, v_num=2, val_loss=0.368, val_acc=0.848, train_acc=0.856]\u001b[A\n",
      "Epoch 12:  98%| | 490/500 [00:01<00:00, 292.97it/s, loss=0.338, v_num=2, val_loss=0.368, val_acc=0.848, train_acc=0.856]\u001b[A\n",
      "Epoch 12:  98%| | 491/500 [00:01<00:00, 293.04it/s, loss=0.338, v_num=2, val_loss=0.368, val_acc=0.848, train_acc=0.856]\u001b[A\n",
      "Epoch 12:  98%| | 492/500 [00:01<00:00, 292.79it/s, loss=0.338, v_num=2, val_loss=0.368, val_acc=0.848, train_acc=0.856]\u001b[A\n",
      "Epoch 12:  99%|| 493/500 [00:01<00:00, 292.80it/s, loss=0.338, v_num=2, val_loss=0.368, val_acc=0.848, train_acc=0.856]\u001b[A\n",
      "Epoch 12:  99%|| 494/500 [00:01<00:00, 292.88it/s, loss=0.338, v_num=2, val_loss=0.368, val_acc=0.848, train_acc=0.856]\u001b[A\n",
      "Epoch 12:  99%|| 495/500 [00:01<00:00, 292.98it/s, loss=0.338, v_num=2, val_loss=0.368, val_acc=0.848, train_acc=0.856]\u001b[A\n",
      "Epoch 12:  99%|| 496/500 [00:01<00:00, 293.12it/s, loss=0.338, v_num=2, val_loss=0.368, val_acc=0.848, train_acc=0.856]\u001b[A\n",
      "Epoch 12:  99%|| 497/500 [00:01<00:00, 293.19it/s, loss=0.338, v_num=2, val_loss=0.368, val_acc=0.848, train_acc=0.856]\u001b[A\n",
      "Epoch 12: 100%|| 498/500 [00:01<00:00, 293.30it/s, loss=0.338, v_num=2, val_loss=0.368, val_acc=0.848, train_acc=0.856]\u001b[A\n",
      "Epoch 12: 100%|| 499/500 [00:01<00:00, 293.38it/s, loss=0.338, v_num=2, val_loss=0.368, val_acc=0.848, train_acc=0.856]\u001b[A\n",
      "Epoch 12: 100%|| 500/500 [00:01<00:00, 292.06it/s, loss=0.338, v_num=2, val_loss=0.371, val_acc=0.841, train_acc=0.856]\u001b[A\n",
      "Epoch 13:  90%|     | 450/500 [00:01<00:00, 296.58it/s, loss=0.344, v_num=2, val_loss=0.371, val_acc=0.841, train_acc=0.857]\u001b[A\n",
      "Validation: 0it [00:00, ?it/s]\u001b[A\n",
      "Validation:   0%|                                                                                                                                        | 0/50 [00:00<?, ?it/s]\u001b[A\n",
      "Validation DataLoader 0:   0%|                                                                                                                           | 0/50 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 13:  90%|     | 451/500 [00:01<00:00, 293.11it/s, loss=0.344, v_num=2, val_loss=0.371, val_acc=0.841, train_acc=0.857]\u001b[A\n",
      "Epoch 13:  90%|     | 452/500 [00:01<00:00, 293.27it/s, loss=0.344, v_num=2, val_loss=0.371, val_acc=0.841, train_acc=0.857]\u001b[A\n",
      "Epoch 13:  91%|     | 453/500 [00:01<00:00, 293.40it/s, loss=0.344, v_num=2, val_loss=0.371, val_acc=0.841, train_acc=0.857]\u001b[A\n",
      "Epoch 13:  91%|     | 454/500 [00:01<00:00, 293.49it/s, loss=0.344, v_num=2, val_loss=0.371, val_acc=0.841, train_acc=0.857]\u001b[A\n",
      "Epoch 13:  91%|     | 455/500 [00:01<00:00, 293.76it/s, loss=0.344, v_num=2, val_loss=0.371, val_acc=0.841, train_acc=0.857]\u001b[A\n",
      "Epoch 13:  91%|     | 456/500 [00:01<00:00, 293.96it/s, loss=0.344, v_num=2, val_loss=0.371, val_acc=0.841, train_acc=0.857]\u001b[A\n",
      "Epoch 13:  91%|     | 457/500 [00:01<00:00, 294.20it/s, loss=0.344, v_num=2, val_loss=0.371, val_acc=0.841, train_acc=0.857]\u001b[A\n",
      "Epoch 13:  92%|    | 458/500 [00:01<00:00, 294.36it/s, loss=0.344, v_num=2, val_loss=0.371, val_acc=0.841, train_acc=0.857]\u001b[A\n",
      "Epoch 13:  92%|    | 459/500 [00:01<00:00, 294.53it/s, loss=0.344, v_num=2, val_loss=0.371, val_acc=0.841, train_acc=0.857]\u001b[A\n",
      "Epoch 13:  92%|    | 460/500 [00:01<00:00, 294.73it/s, loss=0.344, v_num=2, val_loss=0.371, val_acc=0.841, train_acc=0.857]\u001b[A\n",
      "Epoch 13:  92%|    | 461/500 [00:01<00:00, 294.88it/s, loss=0.344, v_num=2, val_loss=0.371, val_acc=0.841, train_acc=0.857]\u001b[A\n",
      "Epoch 13:  92%|    | 462/500 [00:01<00:00, 295.02it/s, loss=0.344, v_num=2, val_loss=0.371, val_acc=0.841, train_acc=0.857]\u001b[A\n",
      "Epoch 13:  93%|    | 463/500 [00:01<00:00, 295.26it/s, loss=0.344, v_num=2, val_loss=0.371, val_acc=0.841, train_acc=0.857]\u001b[A\n",
      "Epoch 13:  93%|    | 464/500 [00:01<00:00, 295.46it/s, loss=0.344, v_num=2, val_loss=0.371, val_acc=0.841, train_acc=0.857]\u001b[A\n",
      "Epoch 13:  93%|    | 465/500 [00:01<00:00, 295.67it/s, loss=0.344, v_num=2, val_loss=0.371, val_acc=0.841, train_acc=0.857]\u001b[A\n",
      "Epoch 13:  93%|    | 466/500 [00:01<00:00, 295.89it/s, loss=0.344, v_num=2, val_loss=0.371, val_acc=0.841, train_acc=0.857]\u001b[A\n",
      "Epoch 13:  93%|   | 467/500 [00:01<00:00, 296.10it/s, loss=0.344, v_num=2, val_loss=0.371, val_acc=0.841, train_acc=0.857]\u001b[A\n",
      "Epoch 13:  94%|   | 468/500 [00:01<00:00, 296.19it/s, loss=0.344, v_num=2, val_loss=0.371, val_acc=0.841, train_acc=0.857]\u001b[A\n",
      "Epoch 13:  94%|   | 469/500 [00:01<00:00, 296.37it/s, loss=0.344, v_num=2, val_loss=0.371, val_acc=0.841, train_acc=0.857]\u001b[A\n",
      "Epoch 13:  94%|   | 470/500 [00:01<00:00, 296.59it/s, loss=0.344, v_num=2, val_loss=0.371, val_acc=0.841, train_acc=0.857]\u001b[A\n",
      "Epoch 13:  94%|   | 471/500 [00:01<00:00, 296.73it/s, loss=0.344, v_num=2, val_loss=0.371, val_acc=0.841, train_acc=0.857]\u001b[A\n",
      "Epoch 13:  94%|   | 472/500 [00:01<00:00, 296.89it/s, loss=0.344, v_num=2, val_loss=0.371, val_acc=0.841, train_acc=0.857]\u001b[A\n",
      "Epoch 13:  95%|   | 473/500 [00:01<00:00, 297.15it/s, loss=0.344, v_num=2, val_loss=0.371, val_acc=0.841, train_acc=0.857]\u001b[A\n",
      "Epoch 13:  95%|   | 474/500 [00:01<00:00, 297.33it/s, loss=0.344, v_num=2, val_loss=0.371, val_acc=0.841, train_acc=0.857]\u001b[A\n",
      "Epoch 13:  95%|  | 475/500 [00:01<00:00, 297.54it/s, loss=0.344, v_num=2, val_loss=0.371, val_acc=0.841, train_acc=0.857]\u001b[A\n",
      "Epoch 13:  95%|  | 476/500 [00:01<00:00, 297.65it/s, loss=0.344, v_num=2, val_loss=0.371, val_acc=0.841, train_acc=0.857]\u001b[A\n",
      "Epoch 13:  95%|  | 477/500 [00:01<00:00, 297.76it/s, loss=0.344, v_num=2, val_loss=0.371, val_acc=0.841, train_acc=0.857]\u001b[A\n",
      "Epoch 13:  96%|  | 478/500 [00:01<00:00, 297.91it/s, loss=0.344, v_num=2, val_loss=0.371, val_acc=0.841, train_acc=0.857]\u001b[A\n",
      "Epoch 13:  96%|  | 479/500 [00:01<00:00, 298.03it/s, loss=0.344, v_num=2, val_loss=0.371, val_acc=0.841, train_acc=0.857]\u001b[A\n",
      "Epoch 13:  96%|  | 480/500 [00:01<00:00, 298.08it/s, loss=0.344, v_num=2, val_loss=0.371, val_acc=0.841, train_acc=0.857]\u001b[A\n",
      "Epoch 13:  96%|  | 481/500 [00:01<00:00, 298.24it/s, loss=0.344, v_num=2, val_loss=0.371, val_acc=0.841, train_acc=0.857]\u001b[A\n",
      "Epoch 13:  96%|  | 482/500 [00:01<00:00, 298.41it/s, loss=0.344, v_num=2, val_loss=0.371, val_acc=0.841, train_acc=0.857]\u001b[A\n",
      "Epoch 13:  97%|  | 483/500 [00:01<00:00, 298.59it/s, loss=0.344, v_num=2, val_loss=0.371, val_acc=0.841, train_acc=0.857]\u001b[A\n",
      "Epoch 13:  97%| | 484/500 [00:01<00:00, 298.76it/s, loss=0.344, v_num=2, val_loss=0.371, val_acc=0.841, train_acc=0.857]\u001b[A\n",
      "Epoch 13:  97%| | 485/500 [00:01<00:00, 298.95it/s, loss=0.344, v_num=2, val_loss=0.371, val_acc=0.841, train_acc=0.857]\u001b[A\n",
      "Epoch 13:  97%| | 486/500 [00:01<00:00, 299.14it/s, loss=0.344, v_num=2, val_loss=0.371, val_acc=0.841, train_acc=0.857]\u001b[A\n",
      "Epoch 13:  97%| | 487/500 [00:01<00:00, 299.25it/s, loss=0.344, v_num=2, val_loss=0.371, val_acc=0.841, train_acc=0.857]\u001b[A\n",
      "Epoch 13:  98%| | 488/500 [00:01<00:00, 299.37it/s, loss=0.344, v_num=2, val_loss=0.371, val_acc=0.841, train_acc=0.857]\u001b[A\n",
      "Epoch 13:  98%| | 489/500 [00:01<00:00, 299.50it/s, loss=0.344, v_num=2, val_loss=0.371, val_acc=0.841, train_acc=0.857]\u001b[A\n",
      "Epoch 13:  98%| | 490/500 [00:01<00:00, 299.67it/s, loss=0.344, v_num=2, val_loss=0.371, val_acc=0.841, train_acc=0.857]\u001b[A\n",
      "Epoch 13:  98%| | 491/500 [00:01<00:00, 299.79it/s, loss=0.344, v_num=2, val_loss=0.371, val_acc=0.841, train_acc=0.857]\u001b[A\n",
      "Epoch 13:  98%| | 492/500 [00:01<00:00, 299.98it/s, loss=0.344, v_num=2, val_loss=0.371, val_acc=0.841, train_acc=0.857]\u001b[A\n",
      "Epoch 13:  99%|| 493/500 [00:01<00:00, 300.15it/s, loss=0.344, v_num=2, val_loss=0.371, val_acc=0.841, train_acc=0.857]\u001b[A\n",
      "Epoch 13:  99%|| 494/500 [00:01<00:00, 300.33it/s, loss=0.344, v_num=2, val_loss=0.371, val_acc=0.841, train_acc=0.857]\u001b[A\n",
      "Epoch 13:  99%|| 495/500 [00:01<00:00, 300.52it/s, loss=0.344, v_num=2, val_loss=0.371, val_acc=0.841, train_acc=0.857]\u001b[A\n",
      "Epoch 13:  99%|| 496/500 [00:01<00:00, 300.68it/s, loss=0.344, v_num=2, val_loss=0.371, val_acc=0.841, train_acc=0.857]\u001b[A\n",
      "Epoch 13:  99%|| 497/500 [00:01<00:00, 300.76it/s, loss=0.344, v_num=2, val_loss=0.371, val_acc=0.841, train_acc=0.857]\u001b[A\n",
      "Epoch 13: 100%|| 498/500 [00:01<00:00, 300.87it/s, loss=0.344, v_num=2, val_loss=0.371, val_acc=0.841, train_acc=0.857]\u001b[A\n",
      "Epoch 13: 100%|| 499/500 [00:01<00:00, 301.01it/s, loss=0.344, v_num=2, val_loss=0.371, val_acc=0.841, train_acc=0.857]\u001b[A\n",
      "Epoch 13: 100%|| 500/500 [00:01<00:00, 298.50it/s, loss=0.344, v_num=2, val_loss=0.365, val_acc=0.848, train_acc=0.857]\u001b[A\n",
      "Epoch 14:  33%|                                      | 164/500 [00:00<00:00, 387.61it/s, loss=0.345, v_num=2, val_loss=0.365, val_acc=0.848, train_acc=0.862]\u001b[A"
     ]
    }
   ],
   "source": [
    "trainer.fit(model=lightning_model, datamodule=dm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d4b7eb3-9f3c-4095-ad85-b37acf4557dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Plot\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "\n",
    "metrics = pd.read_csv(f\"{trainer.logger.log_dir}/metrics.csv\")\n",
    "\n",
    "aggreg_metrics = []\n",
    "agg_col = \"epoch\"\n",
    "for i, dfg in metrics.groupby(agg_col):\n",
    "    agg = dict(dfg.mean())\n",
    "    agg[agg_col] = i\n",
    "    aggreg_metrics.append(agg)\n",
    "\n",
    "df_metrics = pd.DataFrame(aggreg_metrics)\n",
    "df_metrics[[\"train_loss\", \"val_loss\"]].plot(\n",
    "    grid=True, legend=True, xlabel=\"Epoch\", ylabel=\"Loss\"\n",
    ")\n",
    "\n",
    "plt.savefig(\"suggest_loss.pdf\")\n",
    "\n",
    "df_metrics[[\"train_acc\", \"val_acc\"]].plot(\n",
    "    grid=True, legend=True, xlabel=\"Epoch\", ylabel=\"ACC\"\n",
    ")\n",
    "\n",
    "plt.savefig(\"suggest_acc.pdf\")\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "27a7e4b8-a243-4a2b-99a9-35b32dbf0398",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing DataLoader 0: 100%|| 125/125 [00:00<00:00, 427.95it/s]\n",
      "\n",
      "       Test metric             DataLoader 0\n",
      "\n",
      "        test_acc            0.4334999918937683\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[{'test_acc': 0.4334999918937683}]"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainer.test(model=lightning_model, datamodule=dm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d088651-949f-43a0-a33e-ac9a04a8bfa2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "819e5494-430a-45ce-9204-293564ce1a19",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cad0cf33-60f4-4cc4-8985-0ac567fad091",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "conda",
   "language": "python",
   "name": "conda"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
